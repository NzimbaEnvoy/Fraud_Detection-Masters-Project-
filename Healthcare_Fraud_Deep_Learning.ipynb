{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NzimbaEnvoy/Fraud_Detection-Masters-Project-/blob/main/Healthcare_Fraud_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrT0YO4Pzckq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEq1dA2m4SHI"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM, TimeDistributed, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import itertools\n",
        "import shap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "508WA8CW4SJc"
      },
      "outputs": [],
      "source": [
        "# Path to the files\n",
        "base_path = \"/content/drive/MyDrive/Thesis Project\"\n",
        "\n",
        "train_path = os.path.join(base_path, \"train_data_healthcare.csv\")\n",
        "test_path = os.path.join(base_path, \"test_data_healthcare.csv\")\n",
        "\n",
        "# Loading data\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "train_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N59CTAl4SMD"
      },
      "outputs": [],
      "source": [
        "# Separating features and target\n",
        "X_train = train_df.drop(\"PotentialFraud\", axis=1)\n",
        "y_train = train_df[\"PotentialFraud\"]\n",
        "X_test = test_df.drop(\"PotentialFraud\", axis=1)\n",
        "y_test = test_df[\"PotentialFraud\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8zquvoc4qod"
      },
      "source": [
        "## CNN BASELINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRoDhk4G4SOZ"
      },
      "outputs": [],
      "source": [
        "# Reshaping input\n",
        "X_train_cnn = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_cnn  = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYtl_eQh4SRQ"
      },
      "outputs": [],
      "source": [
        "# Defining Early Stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#Defining CNN model\n",
        "\n",
        "cnn_baseline = Sequential()\n",
        "# Block 1\n",
        "cnn_baseline.add(Conv1D(32, 3, activation='relu', padding='same',\n",
        "                        input_shape=(X_train_cnn.shape[1], 1)))\n",
        "cnn_baseline.add(BatchNormalization())\n",
        "cnn_baseline.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
        "cnn_baseline.add(BatchNormalization())\n",
        "cnn_baseline.add(MaxPooling1D(pool_size=2))\n",
        "cnn_baseline.add(Dropout(0.3))\n",
        "\n",
        "# Block 2\n",
        "cnn_baseline.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_baseline.add(BatchNormalization())\n",
        "cnn_baseline.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_baseline.add(BatchNormalization())\n",
        "cnn_baseline.add(MaxPooling1D(pool_size=2))\n",
        "cnn_baseline.add(Dropout(0.3))\n",
        "\n",
        "# Head\n",
        "cnn_baseline.add(Flatten())\n",
        "cnn_baseline.add(Dense(64, activation='relu'))\n",
        "cnn_baseline.add(Dropout(0.4))\n",
        "cnn_baseline.add(Dense(1, activation='sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRW2ZzPy4SUZ"
      },
      "outputs": [],
      "source": [
        "# Compiling model\n",
        "cnn_baseline.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
        ")\n",
        "\n",
        "# Fitting model\n",
        "cnn_baseline.fit( X_train_cnn, y_train, epochs=30,batch_size=64, validation_split=0.2, callbacks=[early_stop], verbose=1)\n",
        "\n",
        "# Predicting & evaluating\n",
        "y_pred_probs_cnn = cnn_baseline.predict(X_test_cnn).flatten()\n",
        "y_pred_cnn = (y_pred_probs_cnn > 0.5).astype(int)\n",
        "\n",
        "cm_cnn = confusion_matrix(y_test, y_pred_cnn)\n",
        "roc_cnn = roc_curve(y_test, y_pred_probs_cnn)\n",
        "auc_cnn = roc_auc_score(y_test, y_pred_probs_cnn)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55YDCyTp472d"
      },
      "source": [
        "CNN + SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ms2RbRgr4SW_"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(random_state=123)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "X_train_smote_cnn = X_train_smote.values.reshape((X_train_smote.shape[0], X_train_smote.shape[1], 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tl6Tndbs4SZm"
      },
      "outputs": [],
      "source": [
        "# Defining Early Stopping\n",
        "early_stop = EarlyStopping( monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
        "\n",
        "# Defining model\n",
        "cnn_smote = Sequential()\n",
        "\n",
        "# Block 1\n",
        "cnn_smote.add(Conv1D(32, 3, activation='relu', padding='same',\n",
        "                     input_shape=(X_train_smote_cnn.shape[1], 1)))\n",
        "cnn_smote.add(BatchNormalization())\n",
        "cnn_smote.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
        "cnn_smote.add(BatchNormalization())\n",
        "cnn_smote.add(MaxPooling1D(pool_size=2))\n",
        "cnn_smote.add(Dropout(0.3))\n",
        "\n",
        "# Block 2\n",
        "cnn_smote.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_smote.add(BatchNormalization())\n",
        "cnn_smote.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_smote.add(BatchNormalization())\n",
        "cnn_smote.add(MaxPooling1D(pool_size=2))\n",
        "cnn_smote.add(Dropout(0.3))\n",
        "\n",
        "# Dense head\n",
        "cnn_smote.add(Flatten())\n",
        "cnn_smote.add(Dense(64, activation='relu'))\n",
        "cnn_smote.add(Dropout(0.4))\n",
        "cnn_smote.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LWoQqW04Scd"
      },
      "outputs": [],
      "source": [
        "# Compiling\n",
        "cnn_smote.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "\n",
        "# Fitting with early stopping\n",
        "cnn_smote.fit(\n",
        "    X_train_smote_cnn,\n",
        "    y_train_smote,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_cnn_smote = cnn_smote.predict(X_test_cnn).flatten()\n",
        "y_pred_cnn_smote = (y_pred_probs_cnn_smote > 0.5).astype(int)\n",
        "\n",
        "cm_cnn_smote = confusion_matrix(y_test, y_pred_cnn_smote)\n",
        "roc_cnn_smote = roc_curve(y_test, y_pred_probs_cnn_smote)\n",
        "auc_cnn_smote = roc_auc_score(y_test, y_pred_probs_cnn_smote)\n",
        "\n",
        "print(\"Confusion Matrix (SMOTE):\")\n",
        "print(cm_cnn_smote)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHbpT7jp5JPF"
      },
      "source": [
        "CNN + ADASYN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_-X9MTn4Shq"
      },
      "outputs": [],
      "source": [
        "adas = ADASYN(random_state=123)\n",
        "X_train_adas, y_train_adas = adas.fit_resample(X_train, y_train)\n",
        "X_train_adas_cnn = X_train_adas.values.reshape((X_train_adas.shape[0], X_train_adas.shape[1], 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkdI7iqj4SkR"
      },
      "outputs": [],
      "source": [
        "# Defining Early Stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
        "\n",
        "# Defining model\n",
        "cnn_adas = Sequential()\n",
        "\n",
        "# Block 1\n",
        "cnn_adas.add(Conv1D(32, 3, activation='relu', padding='same',\n",
        "                    input_shape=(X_train_adas_cnn.shape[1], 1)))\n",
        "cnn_adas.add(BatchNormalization())\n",
        "cnn_adas.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
        "cnn_adas.add(BatchNormalization())\n",
        "cnn_adas.add(MaxPooling1D(pool_size=2))\n",
        "cnn_adas.add(Dropout(0.3))\n",
        "\n",
        "# Block 2\n",
        "cnn_adas.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_adas.add(BatchNormalization())\n",
        "cnn_adas.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_adas.add(BatchNormalization())\n",
        "cnn_adas.add(MaxPooling1D(pool_size=2))\n",
        "cnn_adas.add(Dropout(0.3))\n",
        "\n",
        "# Head\n",
        "cnn_adas.add(Flatten())\n",
        "cnn_adas.add(Dense(64, activation='relu'))\n",
        "cnn_adas.add(Dropout(0.4))\n",
        "cnn_adas.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6BOra_U4SnL"
      },
      "outputs": [],
      "source": [
        "# Compiling model\n",
        "cnn_adas.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                 metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting model with early stopping\n",
        "cnn_adas.fit(\n",
        "    X_train_adas_cnn,\n",
        "    y_train_adas,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluating\n",
        "y_pred_probs_cnn_adas = cnn_adas.predict(X_test_cnn).flatten()\n",
        "y_pred_cnn_adas = (y_pred_probs_cnn_adas > 0.5).astype(int)\n",
        "\n",
        "cm_cnn_adas = confusion_matrix(y_test, y_pred_cnn_adas)\n",
        "roc_cnn_adas = roc_curve(y_test, y_pred_probs_cnn_adas)\n",
        "auc_cnn_adas = roc_auc_score(y_test, y_pred_probs_cnn_adas)\n",
        "\n",
        "print(\"Confusion Matrix (ADASYN):\")\n",
        "print(cm_cnn_adas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFKens4Y5Wk2"
      },
      "source": [
        "Cost-sensitive CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDHbv7fe4StI"
      },
      "outputs": [],
      "source": [
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXRVGdO14SwC"
      },
      "outputs": [],
      "source": [
        "# Defining Early Stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Defining model\n",
        "cnn_cost = Sequential()\n",
        "\n",
        "# Block 1\n",
        "cnn_cost.add(Conv1D(32, 3, activation='relu', padding='same',\n",
        "                    input_shape=(X_train_cnn.shape[1], 1)))\n",
        "cnn_cost.add(BatchNormalization())\n",
        "cnn_cost.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
        "cnn_cost.add(BatchNormalization())\n",
        "cnn_cost.add(MaxPooling1D(pool_size=2))\n",
        "cnn_cost.add(Dropout(0.3))\n",
        "\n",
        "# Block 2\n",
        "cnn_cost.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_cost.add(BatchNormalization())\n",
        "cnn_cost.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_cost.add(BatchNormalization())\n",
        "cnn_cost.add(MaxPooling1D(pool_size=2))\n",
        "cnn_cost.add(Dropout(0.3))\n",
        "\n",
        "# Dense Head\n",
        "cnn_cost.add(Flatten())\n",
        "cnn_cost.add(Dense(64, activation='relu'))\n",
        "cnn_cost.add(Dropout(0.4))\n",
        "cnn_cost.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBCYTfQg4Sy3"
      },
      "outputs": [],
      "source": [
        "# Compiling model\n",
        "cnn_cost.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                 metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting with early stopping and class weights\n",
        "cnn_cost.fit(\n",
        "    X_train_cnn,\n",
        "    y_train,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    class_weight=class_weights_dict,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluating\n",
        "y_pred_probs_cnn_cost = cnn_cost.predict(X_test_cnn).flatten()\n",
        "y_pred_cnn_cost = (y_pred_probs_cnn_cost > 0.5).astype(int)\n",
        "\n",
        "cm_cnn_cost = confusion_matrix(y_test, y_pred_cnn_cost)\n",
        "roc_cnn_cost = roc_curve(y_test, y_pred_probs_cnn_cost)\n",
        "auc_cnn_cost = roc_auc_score(y_test, y_pred_probs_cnn_cost)\n",
        "\n",
        "print(\"Confusion Matrix (Cost-sensitive):\")\n",
        "print(cm_cnn_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToNergdg5mTT"
      },
      "source": [
        "ROC Curve for All CNN Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re-v9Yn44S4X"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(roc_cnn[0], roc_cnn[1], label='Baseline', linewidth=2)\n",
        "plt.plot(roc_cnn_smote[0], roc_cnn_smote[1], label='SMOTE', linewidth=2)\n",
        "plt.plot(roc_cnn_adas[0], roc_cnn_adas[1], label='ADASYN', linewidth=2)\n",
        "plt.plot(roc_cnn_cost[0], roc_cnn_cost[1], label='Cost-sensitive', linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.title('ROC Curves for CNN Models (Healthcare Fraud)')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooRs8ePH5u77"
      },
      "source": [
        "Metrics Comparison Table for CNN Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2ajy8I04S-V"
      },
      "outputs": [],
      "source": [
        "# Computing metrics\n",
        "results_cnn_fraud = pd.DataFrame({\n",
        "    \"Method\": [\"Baseline\", \"SMOTE\", \"ADASYN\", \"Cost-sensitive\"],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_test, y_pred_cnn),\n",
        "        accuracy_score(y_test, y_pred_cnn_smote),\n",
        "        accuracy_score(y_test, y_pred_cnn_adas),\n",
        "        accuracy_score(y_test, y_pred_cnn_cost)\n",
        "    ],\n",
        "    \"Precision\": [\n",
        "        precision_score(y_test, y_pred_cnn),\n",
        "        precision_score(y_test, y_pred_cnn_smote),\n",
        "        precision_score(y_test, y_pred_cnn_adas),\n",
        "        precision_score(y_test, y_pred_cnn_cost)\n",
        "    ],\n",
        "    \"Recall\": [\n",
        "        recall_score(y_test, y_pred_cnn),\n",
        "        recall_score(y_test, y_pred_cnn_smote),\n",
        "        recall_score(y_test, y_pred_cnn_adas),\n",
        "        recall_score(y_test, y_pred_cnn_cost)\n",
        "    ],\n",
        "    \"F1\": [\n",
        "        f1_score(y_test, y_pred_cnn),\n",
        "        f1_score(y_test, y_pred_cnn_smote),\n",
        "        f1_score(y_test, y_pred_cnn_adas),\n",
        "        f1_score(y_test, y_pred_cnn_cost)\n",
        "    ],\n",
        "    \"AUC\": [\n",
        "        auc_cnn,\n",
        "        auc_cnn_smote,\n",
        "        auc_cnn_adas,\n",
        "        auc_cnn_cost\n",
        "    ]\n",
        "\n",
        "})\n",
        "\n",
        "# Show table\n",
        "print(results_cnn_fraud)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSN--1gY56oT"
      },
      "source": [
        "## LSTM MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQCAS1Rr5_cH"
      },
      "source": [
        "LSTM BASELINE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWrMJH0l4TGq"
      },
      "outputs": [],
      "source": [
        "# Reshaping input\n",
        "X_train_lstm = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_lstm  = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkKxDsFL4TLH"
      },
      "outputs": [],
      "source": [
        "# Defining Early Stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Defining model\n",
        "lstm_baseline = Sequential()\n",
        "# Block 1\n",
        "lstm_baseline.add(LSTM(128, input_shape=(X_train_lstm.shape[1], 1),\n",
        "                       return_sequences=True, dropout=0.3, recurrent_dropout=0.1))\n",
        "lstm_baseline.add(BatchNormalization())\n",
        "\n",
        "# Block 2\n",
        "lstm_baseline.add(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1))\n",
        "lstm_baseline.add(BatchNormalization())\n",
        "\n",
        "# Block 3\n",
        "lstm_baseline.add(LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1))\n",
        "lstm_baseline.add(BatchNormalization())\n",
        "\n",
        "# Dense head\n",
        "lstm_baseline.add(Dense(256, activation='relu'))\n",
        "lstm_baseline.add(Dropout(0.4))\n",
        "lstm_baseline.add(Dense(128, activation='relu'))\n",
        "lstm_baseline.add(Dropout(0.3))\n",
        "lstm_baseline.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nx6ovg914TNy"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "lstm_baseline.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy',\n",
        "                      metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting model with early stopping\n",
        "lstm_baseline.fit(\n",
        "    X_train_lstm,\n",
        "    y_train,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluating\n",
        "y_pred_probs_lstm = lstm_baseline.predict(X_test_lstm).flatten()\n",
        "y_pred_lstm = (y_pred_probs_lstm > 0.5).astype(int)\n",
        "\n",
        "cm_lstm = confusion_matrix(y_test, y_pred_lstm)\n",
        "roc_lstm = roc_curve(y_test, y_pred_probs_lstm)\n",
        "auc_lstm = roc_auc_score(y_test, y_pred_probs_lstm)\n",
        "\n",
        "print(\"Confusion Matrix (LSTM Baseline):\")\n",
        "print(cm_lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1C_-A7oAEHg"
      },
      "source": [
        "SHAP ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct6y-6vW4TQN"
      },
      "outputs": [],
      "source": [
        "#Feature Names\n",
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "#Sample Background & Test Data\n",
        "background_lstm = X_train_lstm[np.random.choice(X_train_lstm.shape[0], 100, replace=False)]\n",
        "X_explain_lstm = X_test_lstm[np.random.choice(X_test_lstm.shape[0], 50, replace=False)]\n",
        "\n",
        "#Flatten for KernelExplainer\n",
        "background_lstm_flat = background_lstm.reshape(background_lstm.shape[0], -1)\n",
        "X_explain_lstm_flat = X_explain_lstm.reshape(X_explain_lstm.shape[0], -1)\n",
        "\n",
        "#Defining Wrapper Function\n",
        "def lstm_predict(x_flat):\n",
        "    x_reshaped = x_flat.reshape((-1, X_train_lstm.shape[1], 1))\n",
        "    return lstm_baseline.predict(x_reshaped).flatten()\n",
        "\n",
        "#Creating SHAP Explainer\n",
        "explainer_lstm = shap.KernelExplainer(lstm_predict, background_lstm_flat)\n",
        "\n",
        "#Computing SHAP Values\n",
        "shap_values_lstm = explainer_lstm.shap_values(X_explain_lstm_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pnZHgc2AC7t"
      },
      "outputs": [],
      "source": [
        "#SHAP Summary Plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "shap.summary_plot(\n",
        "    shap_values_lstm,\n",
        "    X_explain_lstm_flat,\n",
        "    feature_names=feature_names,\n",
        "    plot_type=\"dot\"\n",
        ")\n",
        "plt.title(\"SHAP Summary Plot - LSTM (Baseline)\", fontsize=12)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLAR-Eqy6O4K"
      },
      "source": [
        "LSTM + SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGS2vYpM4TT7"
      },
      "outputs": [],
      "source": [
        "X_train_smote_lstm = X_train_smote.values.reshape((X_train_smote.shape[0], X_train_smote.shape[1], 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWN6U3fH4TXG"
      },
      "outputs": [],
      "source": [
        "# Defining Early Stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Defining model\n",
        "lstm_smote = Sequential()\n",
        "\n",
        "# LSTM Block 1\n",
        "lstm_smote.add(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1,\n",
        "                    input_shape=(X_train_smote_lstm.shape[1], 1)))\n",
        "lstm_smote.add(BatchNormalization())\n",
        "\n",
        "# LSTM Block 2\n",
        "lstm_smote.add(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1))\n",
        "lstm_smote.add(BatchNormalization())\n",
        "\n",
        "# LSTM Block 3\n",
        "lstm_smote.add(LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1))\n",
        "lstm_smote.add(BatchNormalization())\n",
        "\n",
        "# Dense head\n",
        "lstm_smote.add(Dense(256, activation='relu'))\n",
        "lstm_smote.add(Dropout(0.4))\n",
        "lstm_smote.add(Dense(128, activation='relu'))\n",
        "lstm_smote.add(Dropout(0.3))\n",
        "lstm_smote.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVY66d6E4TaA"
      },
      "outputs": [],
      "source": [
        "# Compiling model\n",
        "lstm_smote.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy',\n",
        "                   metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting model with early stopping\n",
        "lstm_smote.fit(\n",
        "    X_train_smote_lstm,\n",
        "    y_train_smote,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluating\n",
        "y_pred_probs_lstm_smote = lstm_smote.predict(X_test_lstm).flatten()\n",
        "y_pred_lstm_smote = (y_pred_probs_lstm_smote > 0.5).astype(int)\n",
        "\n",
        "cm_lstm_smote = confusion_matrix(y_test, y_pred_lstm_smote)\n",
        "roc_lstm_smote = roc_curve(y_test, y_pred_probs_lstm_smote)\n",
        "auc_lstm_smote = roc_auc_score(y_test, y_pred_probs_lstm_smote)\n",
        "\n",
        "print(\"Confusion Matrix (LSTM + SMOTE):\")\n",
        "print(cm_lstm_smote)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_fpnr4VAr_9"
      },
      "source": [
        "SHAP ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZkxPMHeAqYT"
      },
      "outputs": [],
      "source": [
        "#Feature Names\n",
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "#Sample background and test instances\n",
        "background_smote_lstm = X_train_smote_lstm[np.random.choice(X_train_smote_lstm.shape[0], 100, replace=False)]\n",
        "X_explain_smote_lstm = X_test_lstm[np.random.choice(X_test_lstm.shape[0], 50, replace=False)]\n",
        "\n",
        "#Flattening for SHAP KernelExplainer\n",
        "background_smote_flat = background_smote_lstm.reshape(background_smote_lstm.shape[0], -1)\n",
        "X_explain_smote_flat = X_explain_smote_lstm.reshape(X_explain_smote_lstm.shape[0], -1)\n",
        "\n",
        "#Wrapper function for SHAP\n",
        "def lstm_smote_predict(x_flat):\n",
        "    x_reshaped = x_flat.reshape((-1, X_train_smote_lstm.shape[1], 1))\n",
        "    return lstm_smote.predict(x_reshaped).flatten()\n",
        "\n",
        "#Creating SHAP KernelExplainer\n",
        "explainer_lstm_smote = shap.KernelExplainer(lstm_smote_predict, background_smote_flat)\n",
        "\n",
        "#Computing SHAP values\n",
        "shap_values_lstm_smote = explainer_lstm_smote.shap_values(X_explain_smote_flat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDYGHzsiAqbX"
      },
      "outputs": [],
      "source": [
        "#SHAP Summary Plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "shap.summary_plot(\n",
        "    shap_values_lstm_smote,\n",
        "    X_explain_smote_flat,\n",
        "    feature_names=feature_names,\n",
        "    plot_type=\"dot\"\n",
        ")\n",
        "plt.title(\"SHAP Summary Plot - LSTM (SMOTE)\", fontsize=10)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zBWuLV563X-"
      },
      "source": [
        "LSTM + ADASYN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZRC-eVA4Tg3"
      },
      "outputs": [],
      "source": [
        "X_train_adas_lstm = X_train_adas.values.reshape((X_train_adas.shape[0], X_train_adas.shape[1], 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFCX3j9C4Tj5"
      },
      "outputs": [],
      "source": [
        "# Defining Early Stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Defining model\n",
        "\n",
        "lstm_adas = Sequential()\n",
        "\n",
        "# LSTM Block 1\n",
        "lstm_adas.add(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1,\n",
        "                   input_shape=(X_train_adas_lstm.shape[1], 1)))\n",
        "lstm_adas.add(BatchNormalization())\n",
        "\n",
        "# LSTM Block 2\n",
        "lstm_adas.add(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1))\n",
        "lstm_adas.add(BatchNormalization())\n",
        "\n",
        "# LSTM Block 3\n",
        "lstm_adas.add(LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1))\n",
        "lstm_adas.add(BatchNormalization())\n",
        "\n",
        "# Dense head\n",
        "lstm_adas.add(Dense(256, activation='relu'))\n",
        "lstm_adas.add(Dropout(0.4))\n",
        "lstm_adas.add(Dense(128, activation='relu'))\n",
        "lstm_adas.add(Dropout(0.3))\n",
        "lstm_adas.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azeJhMfc4Tnz"
      },
      "outputs": [],
      "source": [
        "# Compiling model\n",
        "lstm_adas.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "\n",
        "# Fitting model with early stopping\n",
        "lstm_adas.fit(\n",
        "    X_train_adas_lstm,\n",
        "    y_train_adas,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluating\n",
        "y_pred_probs_lstm_adas = lstm_adas.predict(X_test_lstm).flatten()\n",
        "y_pred_lstm_adas = (y_pred_probs_lstm_adas > 0.5).astype(int)\n",
        "\n",
        "cm_lstm_adas = confusion_matrix(y_test, y_pred_lstm_adas)\n",
        "roc_lstm_adas = roc_curve(y_test, y_pred_probs_lstm_adas)\n",
        "auc_lstm_adas = roc_auc_score(y_test, y_pred_probs_lstm_adas)\n",
        "\n",
        "print(\"Confusion Matrix (LSTM + ADASYN):\")\n",
        "print(cm_lstm_adas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3aZzs5FBrFc"
      },
      "source": [
        "SHAP ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofUCghVw4TrL"
      },
      "outputs": [],
      "source": [
        "#Extracting original feature names\n",
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "#Sample background and explanation sets\n",
        "background_adas_lstm = X_train_adas_lstm[np.random.choice(X_train_adas_lstm.shape[0], 100, replace=False)]\n",
        "X_explain_adas_lstm = X_test_lstm[np.random.choice(X_test_lstm.shape[0], 50, replace=False)]\n",
        "\n",
        "#Flattening for KernelExplainer\n",
        "background_adas_flat = background_adas_lstm.reshape(background_adas_lstm.shape[0], -1)\n",
        "X_explain_adas_flat = X_explain_adas_lstm.reshape(X_explain_adas_lstm.shape[0], -1)\n",
        "\n",
        "#Defining model wrapper for SHAP ---\n",
        "def lstm_adas_predict(x_flat):\n",
        "    x_reshaped = x_flat.reshape((-1, X_train_adas_lstm.shape[1], 1))\n",
        "    return lstm_adas.predict(x_reshaped).flatten()\n",
        "\n",
        "#Creating SHAP KernelExplainer\n",
        "explainer_lstm_adas = shap.KernelExplainer(lstm_adas_predict, background_adas_flat)\n",
        "\n",
        "#Computing SHAP values\n",
        "shap_values_lstm_adas = explainer_lstm_adas.shap_values(X_explain_adas_flat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoWRke6dBqA3"
      },
      "outputs": [],
      "source": [
        "#SHAP Summary Plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "shap.summary_plot(\n",
        "    shap_values_lstm_adas,\n",
        "    X_explain_adas_flat,\n",
        "    feature_names=feature_names,\n",
        "    plot_type=\"dot\"\n",
        ")\n",
        "plt.title(\"SHAP Summary Plot - LSTM (ADASYN)\", fontsize=10)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSINl1dWBqFQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyu889aa7JtL"
      },
      "source": [
        "Cost-sensitive LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxZpZrPi4Tuz"
      },
      "outputs": [],
      "source": [
        "# Defining Early Stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Defining model\n",
        "\n",
        "lstm_cost = Sequential()\n",
        "\n",
        "# LSTM Block 1\n",
        "lstm_cost.add(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1,\n",
        "                   input_shape=(X_train_lstm.shape[1], 1)))\n",
        "lstm_cost.add(BatchNormalization())\n",
        "\n",
        "# LSTM Block 2\n",
        "lstm_cost.add(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1))\n",
        "lstm_cost.add(BatchNormalization())\n",
        "\n",
        "# LSTM Block 3\n",
        "lstm_cost.add(LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1))\n",
        "lstm_cost.add(BatchNormalization())\n",
        "\n",
        "# Dense head\n",
        "lstm_cost.add(Dense(256, activation='relu'))\n",
        "lstm_cost.add(Dropout(0.4))\n",
        "lstm_cost.add(Dense(128, activation='relu'))\n",
        "lstm_cost.add(Dropout(0.3))\n",
        "lstm_cost.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hog_F3tQ4Txn"
      },
      "outputs": [],
      "source": [
        "# Compiling model\n",
        "lstm_cost.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting model with early stopping and class weights\n",
        "lstm_cost.fit(\n",
        "    X_train_lstm,\n",
        "    y_train,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    class_weight=class_weights_dict,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_lstm_cost = lstm_cost.predict(X_test_lstm).flatten()\n",
        "y_pred_lstm_cost = (y_pred_probs_lstm_cost > 0.5).astype(int)\n",
        "\n",
        "cm_lstm_cost = confusion_matrix(y_test, y_pred_lstm_cost)\n",
        "roc_lstm_cost = roc_curve(y_test, y_pred_probs_lstm_cost)\n",
        "auc_lstm_cost = roc_auc_score(y_test, y_pred_probs_lstm_cost)\n",
        "\n",
        "print(\"Confusion Matrix (LSTM Cost-sensitive):\")\n",
        "print(cm_lstm_cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmuYhOuPPJcZ"
      },
      "outputs": [],
      "source": [
        "# Saving the trained LSTM model to an HDF5 file\n",
        "lstm_cost.save(\"lstm_cost_model.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REALTIME INFERENCE"
      ],
      "metadata": {
        "id": "Lz8nvPhcl59C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Loading saved LSTM model\n",
        "lstm_model = load_model(\"/content/drive/My Drive/Thesis Project/lstm_cost_model.h5\")\n",
        "\n",
        "X_test_np = X_test.values.astype(\"float32\")\n",
        "y_test_np = y_test.values.astype(\"int32\")\n",
        "\n",
        "if X_test_np.ndim == 2:\n",
        "    X_test_np = X_test_np.reshape((X_test_np.shape[0], X_test_np.shape[1], 1))\n",
        "\n",
        "fraud_idx = np.where(y_test_np == 1)[0]\n",
        "assert fraud_idx.size > 0, \"No fraud rows in test set.\"\n",
        "fraud_pool_X = X_test_np[fraud_idx]\n",
        "\n",
        "#Simulation settings\n",
        "domain_name  = \"healthcare\"\n",
        "lambda_fraud = 4.0667\n",
        "runs         = 10000\n",
        "threshold    = 0.50\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "#Monte Carlo\n",
        "arrivals_F   = rng.poisson(lam=lambda_fraud, size=runs)\n",
        "tp_vec       = np.zeros(runs, dtype=int)\n",
        "det_rate_pct = np.full(runs, np.nan, dtype=float)\n",
        "\n",
        "for r in range(runs):\n",
        "    F = arrivals_F[r]\n",
        "    if F == 0:\n",
        "        continue\n",
        "    s_idx = rng.choice(fraud_pool_X.shape[0], size=F, replace=True)\n",
        "    X_r   = fraud_pool_X[s_idx]\n",
        "\n",
        "    # Predicting probabilities; assumes model outputs sigmoid probabilities\n",
        "    p_r  = lstm_model.predict(X_r, verbose=0).reshape(-1)\n",
        "    yhat = (p_r >= threshold).astype(int)\n",
        "\n",
        "    TP = int(yhat.sum())\n",
        "    tp_vec[r]       = TP\n",
        "    det_rate_pct[r] = 100.0 * TP / F\n",
        "\n",
        "#Results frame\n",
        "mc_df = pd.DataFrame({\n",
        "    \"run\": np.arange(1, runs+1),\n",
        "    \"fraud_arrivals\": arrivals_F,\n",
        "    \"tp\": tp_vec,\n",
        "    \"detection_pct\": det_rate_pct\n",
        "})\n",
        "plot_df = mc_df.dropna(subset=[\"detection_pct\"])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IhXKlfcEiyXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary table\n",
        "summary_table = pd.DataFrame([{\n",
        "    \"model\": \"LSTM (Cost-Sensitive)\",\n",
        "    \"threshold\": threshold,\n",
        "    \"mean_detection_pct\": plot_df[\"detection_pct\"].mean(),\n",
        "    \"median_detection_pct\": plot_df[\"detection_pct\"].median(),\n",
        "    \"p05_detection_pct\": np.percentile(plot_df[\"detection_pct\"], 5),\n",
        "    \"p95_detection_pct\": np.percentile(plot_df[\"detection_pct\"], 95),\n",
        "    \"mean_tp_per_sec\": lambda_fraud * plot_df[\"detection_pct\"].mean() / 100.0,\n",
        "    \"p05_tp_per_sec\":  lambda_fraud * np.percentile(plot_df[\"detection_pct\"], 5)  / 100.0,\n",
        "    \"p95_tp_per_sec\":  lambda_fraud * np.percentile(plot_df[\"detection_pct\"], 95) / 100.0\n",
        "}])\n",
        "\n",
        "print(summary_table.to_string(index=False))"
      ],
      "metadata": {
        "id": "9YJ-9RvAiyai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.hist(plot_df[\"detection_pct\"].values, bins=40)\n",
        "plt.title(f\"Detection rate per second — Monte Carlo ({domain_name})\")\n",
        "plt.xlabel(\"Detection Rate per second (%)\")\n",
        "plt.ylabel(\"Count of runs\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dAEMK3qtiydU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ECDF\n",
        "x = np.sort(plot_df[\"detection_pct\"].values)\n",
        "y = np.arange(1, x.size+1) / x.size\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(x, y)\n",
        "plt.title(f\"ECDF of per-second detection — Monte Carlo ({domain_name})\")\n",
        "plt.xlabel(\"Detection Rate per second (%)\")\n",
        "plt.ylabel(\"ECDF\")\n",
        "plt.ylim(0, 1)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XVO3sHY7iygH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "# 1) Loading model + test data\n",
        "lstm_model = load_model(\"/content/drive/My Drive/Thesis Project/lstm_cost_model.h5\")\n",
        "\n",
        "X_test_np = X_test.values.astype(\"float32\") if hasattr(X_test, \"values\") else np.asarray(X_test, dtype=\"float32\")\n",
        "y_test_np = y_test.values.astype(\"int32\")   if hasattr(y_test, \"values\") else np.asarray(y_test, dtype=\"int32\")\n",
        "\n",
        "# labels\n",
        "assert set(np.unique(y_test_np)).issubset({0, 1}), \"y_test must be binary {0,1}\"\n",
        "assert X_test_np.shape[0] == y_test_np.shape[0]\n",
        "\n",
        "# If LSTM expects\n",
        "def _ensure_rnn_shape(model, X):\n",
        "    \"\"\"\n",
        "    If model.input_shape is (None, T, C) and X is (n, T), expand to (n, T, 1).\n",
        "    If already 3D, leave as-is.\n",
        "    \"\"\"\n",
        "    in_shape = model.input_shape\n",
        "    if X.ndim == 2 and len(in_shape) == 3:\n",
        "        return np.expand_dims(X, axis=-1)\n",
        "    return X\n",
        "\n",
        "X_test_np = _ensure_rnn_shape(lstm_model, X_test_np)\n",
        "\n",
        "#Simulation settings\n",
        "lambda_per_sec = 4.0667\n",
        "runs           = 10000\n",
        "thr_lstm       = 0.50\n",
        "rng            = np.random.default_rng(123)"
      ],
      "metadata": {
        "id": "LgvbWz08iyl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probability helper\n",
        "\n",
        "def predict_prob_keras(model, X_batch, batch_size=4096):\n",
        "    \"\"\"Return p(y=1) for a Keras model (handles (n,1) or (n,) outputs).\"\"\"\n",
        "    p = model.predict(X_batch, batch_size=batch_size, verbose=0)\n",
        "    return np.asarray(p).reshape(-1)"
      ],
      "metadata": {
        "id": "3puRSbO_iyoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Monte Carlo simulator\n",
        "def simulate_realtime_fullpool_keras(model, threshold, lambda_rate_per_sec, runs,\n",
        "                                     X_pool, y_pool, window_secs=1):\n",
        "    \"\"\"\n",
        "    Each run is a window of length `window_secs`.\n",
        "    arrivals ~ Poisson(lambda_rate_per_sec * window_secs)\n",
        "    \"\"\"\n",
        "    N = X_pool.shape[0]\n",
        "    arrivals = rng.poisson(lam=lambda_rate_per_sec * window_secs, size=runs)\n",
        "\n",
        "    TP = np.zeros(runs, dtype=np.int32)\n",
        "    FP = np.zeros(runs, dtype=np.int32)\n",
        "    TN = np.zeros(runs, dtype=np.int32)\n",
        "    FN = np.zeros(runs, dtype=np.int32)\n",
        "\n",
        "    precision = np.full(runs, np.nan)\n",
        "    recall    = np.full(runs, np.nan)\n",
        "    accuracy  = np.full(runs, np.nan)\n",
        "    f1        = np.full(runs, np.nan)\n",
        "    auc_vec   = np.full(runs, np.nan)\n",
        "\n",
        "    for r in range(runs):\n",
        "        F = arrivals[r]\n",
        "        if F == 0:\n",
        "            continue\n",
        "\n",
        "        idx  = rng.integers(0, N, size=F, dtype=np.int64)\n",
        "        X_r  = X_pool[idx]\n",
        "        y_r  = y_pool[idx]\n",
        "        p_r  = predict_prob_keras(model, X_r)\n",
        "        yhat = (p_r >= threshold).astype(np.int32)\n",
        "\n",
        "        tp = np.sum((yhat == 1) & (y_r == 1))\n",
        "        fp = np.sum((yhat == 1) & (y_r == 0))\n",
        "        tn = np.sum((yhat == 0) & (y_r == 0))\n",
        "        fn = np.sum((yhat == 0) & (y_r == 1))\n",
        "\n",
        "        TP[r], FP[r], TN[r], FN[r] = tp, fp, tn, fn\n",
        "\n",
        "        if (tp + fp) > 0:\n",
        "            precision[r] = tp / (tp + fp)\n",
        "        if (tp + fn) > 0:\n",
        "            recall[r] = tp / (tp + fn)\n",
        "\n",
        "        accuracy[r] = (tp + tn) / F\n",
        "        if not np.isnan(precision[r]) and not np.isnan(recall[r]) and (precision[r] + recall[r]) > 0:\n",
        "            f1[r] = 2 * precision[r] * recall[r] / (precision[r] + recall[r])\n",
        "\n",
        "        # AUC only if both classes present in the window\n",
        "        if (y_r.min() == 0) and (y_r.max() == 1):\n",
        "            try:\n",
        "                auc_vec[r] = roc_auc_score(y_r, p_r)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    mc_df = pd.DataFrame({\n",
        "        \"run\": np.arange(1, runs+1, dtype=np.int32),\n",
        "        \"window_secs\": window_secs,\n",
        "        \"arrivals\": arrivals,\n",
        "        \"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN,\n",
        "        \"precision\": precision, \"recall\": recall, \"accuracy\": accuracy, \"f1\": f1,\n",
        "        \"auc\": auc_vec\n",
        "    })\n",
        "\n",
        "    summary = {\n",
        "        \"runs\": runs,\n",
        "        \"window_secs\": window_secs,\n",
        "        \"runs_with_tx\": int(np.sum(arrivals > 0)),\n",
        "        \"mean_TP\": float(np.nanmean(TP)),\n",
        "        \"mean_FP\": float(np.nanmean(FP)),\n",
        "        \"mean_TN\": float(np.nanmean(TN)),\n",
        "        \"mean_FN\": float(np.nanmean(FN)),\n",
        "        \"mean_precision\": float(np.nanmean(precision)),\n",
        "        \"mean_recall\": float(np.nanmean(recall)),\n",
        "        \"mean_accuracy\": float(np.nanmean(accuracy)),\n",
        "        \"mean_f1\": float(np.nanmean(f1)),\n",
        "        \"mean_auc\": float(np.nanmean(auc_vec)),\n",
        "        \"median_auc\": float(np.nanmedian(auc_vec)),\n",
        "        \"n_auc_runs\": int(np.sum(~np.isnan(auc_vec))),\n",
        "    }\n",
        "    summary_df = pd.DataFrame([summary])\n",
        "    return {\"mc_df\": mc_df, \"summary\": summary_df}"
      ],
      "metadata": {
        "id": "0NI6F9zCiyrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run LSTM at 1s and 10s windows\n",
        "res_lstm_1s  = simulate_realtime_fullpool_keras(\n",
        "    model=lstm_model, threshold=thr_lstm, lambda_rate_per_sec=lambda_per_sec,\n",
        "    runs=runs, X_pool=X_test_np, y_pool=y_test_np, window_secs=1\n",
        ")\n",
        "res_lstm_10s = simulate_realtime_fullpool_keras(\n",
        "    model=lstm_model, threshold=thr_lstm, lambda_rate_per_sec=lambda_per_sec,\n",
        "    runs=runs, X_pool=X_test_np, y_pool=y_test_np, window_secs=10\n",
        ")"
      ],
      "metadata": {
        "id": "Ujp_WMkziyuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparing summaries\n",
        "summary_table = pd.concat([\n",
        "    res_lstm_1s[\"summary\"].assign(model=\"LSTM (Healthcare)\", time_unit=\"1 sec\",  threshold=thr_lstm),\n",
        "    res_lstm_10s[\"summary\"].assign(model=\"LSTM (Healthcare)\", time_unit=\"10 sec\", threshold=thr_lstm),\n",
        "], ignore_index=True)[[\n",
        "    \"model\",\"time_unit\",\n",
        "    \"mean_accuracy\",\"mean_precision\",\"mean_recall\",\"mean_f1\",\n",
        "    \"mean_auc\"\n",
        "]]\n",
        "\n",
        "print(summary_table.to_string(index=False))"
      ],
      "metadata": {
        "id": "uHs2tdS8iyxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy25llxYCKm7"
      },
      "source": [
        "SHAP ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEwkvBns4T0v"
      },
      "outputs": [],
      "source": [
        "#Extracting original feature names\n",
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "#Sample background and explanation sets\n",
        "background_lstm_cost = X_train_lstm[np.random.choice(X_train_lstm.shape[0], 100, replace=False)]\n",
        "X_explain_lstm_cost = X_test_lstm[np.random.choice(X_test_lstm.shape[0], 50, replace=False)]\n",
        "\n",
        "#Flattening for KernelExplainer\n",
        "background_lstm_cost_flat = background_lstm_cost.reshape(background_lstm_cost.shape[0], -1)\n",
        "X_explain_lstm_cost_flat = X_explain_lstm_cost.reshape(X_explain_lstm_cost.shape[0], -1)\n",
        "\n",
        "#Defining model prediction wrapper\n",
        "def lstm_cost_predict(x_flat):\n",
        "    x_reshaped = x_flat.reshape((-1, X_train_lstm.shape[1], 1))\n",
        "    return lstm_cost.predict(x_reshaped).flatten()\n",
        "\n",
        "#Creating SHAP KernelExplainer\n",
        "explainer_lstm_cost = shap.KernelExplainer(lstm_cost_predict, background_lstm_cost_flat)\n",
        "\n",
        "#Computing SHAP values\n",
        "shap_values_lstm_cost = explainer_lstm_cost.shap_values(X_explain_lstm_cost_flat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCUCnSlxCJsO"
      },
      "outputs": [],
      "source": [
        "#Plot SHAP summary\n",
        "plt.figure(figsize=(6, 6))\n",
        "shap.summary_plot(\n",
        "    shap_values_lstm_cost,\n",
        "    X_explain_lstm_cost_flat,\n",
        "    feature_names=feature_names,\n",
        "    plot_type=\"dot\"\n",
        ")\n",
        "plt.title(\"SHAP Summary Plot - LSTM (Cost-sensitive)\", fontsize=10)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ5PYT5L7XSZ"
      },
      "source": [
        "ROC Curve for All LSTM Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_b4_KYY4T3Y"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(roc_lstm[0], roc_lstm[1], label='Baseline', linewidth=2)\n",
        "plt.plot(roc_lstm_smote[0], roc_lstm_smote[1], label='SMOTE', linewidth=2)\n",
        "plt.plot(roc_lstm_adas[0], roc_lstm_adas[1], label='ADASYN', linewidth=2)\n",
        "plt.plot(roc_lstm_cost[0], roc_lstm_cost[1], label='Cost-sensitive', linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.title('ROC Curves for LSTM Models (Healthcare Fraud)')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4JOFIe_7gEI"
      },
      "source": [
        "Metrics Comparison Table for LSTM Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO35-Scc4T8n"
      },
      "outputs": [],
      "source": [
        "results_lstm_fraud = pd.DataFrame({\n",
        "    \"Method\": [\"Baseline\", \"SMOTE\", \"ADASYN\", \"Cost-sensitive\"],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_test, y_pred_lstm),\n",
        "        accuracy_score(y_test, y_pred_lstm_smote),\n",
        "        accuracy_score(y_test, y_pred_lstm_adas),\n",
        "        accuracy_score(y_test, y_pred_lstm_cost)\n",
        "    ],\n",
        "    \"Precision\": [\n",
        "        precision_score(y_test, y_pred_lstm),\n",
        "        precision_score(y_test, y_pred_lstm_smote),\n",
        "        precision_score(y_test, y_pred_lstm_adas),\n",
        "        precision_score(y_test, y_pred_lstm_cost)\n",
        "    ],\n",
        "    \"Recall\": [\n",
        "        recall_score(y_test, y_pred_lstm),\n",
        "        recall_score(y_test, y_pred_lstm_smote),\n",
        "        recall_score(y_test, y_pred_lstm_adas),\n",
        "        recall_score(y_test, y_pred_lstm_cost)\n",
        "    ],\n",
        "    \"F1\": [\n",
        "        f1_score(y_test, y_pred_lstm),\n",
        "        f1_score(y_test, y_pred_lstm_smote),\n",
        "        f1_score(y_test, y_pred_lstm_adas),\n",
        "        f1_score(y_test, y_pred_lstm_cost)\n",
        "    ],\n",
        "    \"AUC\": [\n",
        "        auc_lstm,\n",
        "        auc_lstm_smote,\n",
        "        auc_lstm_adas,\n",
        "        auc_lstm_cost\n",
        "    ]\n",
        "})\n",
        "print(results_lstm_fraud)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hybrid Model"
      ],
      "metadata": {
        "id": "Pelzd6CpZeAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN + LSTM BASELINE MODEL"
      ],
      "metadata": {
        "id": "NEzH44GsZxnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping input\n",
        "X_train_hybrid = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_hybrid  = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))"
      ],
      "metadata": {
        "id": "LB41j9u1ZeaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Early Stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Defining model\n",
        "cnn_lstm_baseline = Sequential()\n",
        "\n",
        "# Conv Block 1\n",
        "cnn_lstm_baseline.add(Conv1D(32, 3, activation='relu', padding='same',\n",
        "                             input_shape=(X_train_hybrid.shape[1], 1)))\n",
        "cnn_lstm_baseline.add(BatchNormalization())\n",
        "cnn_lstm_baseline.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
        "cnn_lstm_baseline.add(BatchNormalization())\n",
        "cnn_lstm_baseline.add(MaxPooling1D(pool_size=2))\n",
        "cnn_lstm_baseline.add(Dropout(0.3))\n",
        "\n",
        "# Conv Block 2\n",
        "cnn_lstm_baseline.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_lstm_baseline.add(BatchNormalization())\n",
        "cnn_lstm_baseline.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_lstm_baseline.add(BatchNormalization())\n",
        "cnn_lstm_baseline.add(MaxPooling1D(pool_size=2))\n",
        "cnn_lstm_baseline.add(Dropout(0.3))\n",
        "\n",
        "# LSTM stack\n",
        "cnn_lstm_baseline.add(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1))\n",
        "cnn_lstm_baseline.add(BatchNormalization())\n",
        "cnn_lstm_baseline.add(LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1))\n",
        "cnn_lstm_baseline.add(BatchNormalization())\n",
        "\n",
        "# Dense head\n",
        "cnn_lstm_baseline.add(Dense(128, activation='relu'))\n",
        "cnn_lstm_baseline.add(Dropout(0.4))\n",
        "cnn_lstm_baseline.add(Dense(64, activation='relu'))\n",
        "cnn_lstm_baseline.add(Dropout(0.3))\n",
        "cnn_lstm_baseline.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "7cAfgDwaZegc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "cnn_lstm_baseline.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                          metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "\n",
        "# Fitting model with early stopping\n",
        "cnn_lstm_baseline.fit(\n",
        "    X_train_hybrid,\n",
        "    y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_hybrid = cnn_lstm_baseline.predict(X_test_hybrid).flatten()\n",
        "y_pred_hybrid = (y_pred_probs_hybrid > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "RpJd6-_yZejP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_hybrid = confusion_matrix(y_test, y_pred_hybrid)\n",
        "roc_hybrid = roc_curve(y_test, y_pred_probs_hybrid)\n",
        "auc_hybrid = roc_auc_score(y_test, y_pred_probs_hybrid)\n",
        "\n",
        "print(\"Confusion Matrix (CNN+LSTM Baseline):\")\n",
        "print(cm_hybrid)"
      ],
      "metadata": {
        "id": "CaCvgCMhZel1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN + LSTM + SMOTE"
      ],
      "metadata": {
        "id": "k59zYkgaZ9nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_smote_hybrid = X_train_smote.values.reshape((X_train_smote.shape[0], X_train_smote.shape[1], 1))\n"
      ],
      "metadata": {
        "id": "1iYxuK1OZeod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Early Stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Defining model\n",
        "cnn_lstm_smote = Sequential()\n",
        "\n",
        "# Conv Block 1\n",
        "cnn_lstm_smote.add(Conv1D(32, 3, activation='relu', padding='same',\n",
        "                          input_shape=(X_train_smote_hybrid.shape[1], 1)))\n",
        "cnn_lstm_smote.add(BatchNormalization())\n",
        "cnn_lstm_smote.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
        "cnn_lstm_smote.add(BatchNormalization())\n",
        "cnn_lstm_smote.add(MaxPooling1D(pool_size=2))\n",
        "cnn_lstm_smote.add(Dropout(0.3))\n",
        "\n",
        "# Conv Block 2\n",
        "cnn_lstm_smote.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_lstm_smote.add(BatchNormalization())\n",
        "cnn_lstm_smote.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_lstm_smote.add(BatchNormalization())\n",
        "cnn_lstm_smote.add(MaxPooling1D(pool_size=2))\n",
        "cnn_lstm_smote.add(Dropout(0.3))\n",
        "\n",
        "# LSTM stack\n",
        "cnn_lstm_smote.add(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1))\n",
        "cnn_lstm_smote.add(BatchNormalization())\n",
        "cnn_lstm_smote.add(LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1))\n",
        "cnn_lstm_smote.add(BatchNormalization())\n",
        "\n",
        "# Dense head\n",
        "cnn_lstm_smote.add(Dense(128, activation='relu'))\n",
        "cnn_lstm_smote.add(Dropout(0.4))\n",
        "cnn_lstm_smote.add(Dense(64, activation='relu'))\n",
        "cnn_lstm_smote.add(Dropout(0.3))\n",
        "cnn_lstm_smote.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "D48MxZlZZerC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "cnn_lstm_smote.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                       metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "\n",
        "# Fitting model with early stopping\n",
        "cnn_lstm_smote.fit(\n",
        "    X_train_smote_hybrid,\n",
        "    y_train_smote,\n",
        "    epochs=3,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_hybrid_smote = cnn_lstm_smote.predict(X_test_hybrid).flatten()\n",
        "y_pred_hybrid_smote = (y_pred_probs_hybrid_smote > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "gTuWLkOLZetp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_hybrid_smote = confusion_matrix(y_test, y_pred_hybrid_smote)\n",
        "roc_hybrid_smote = roc_curve(y_test, y_pred_probs_hybrid_smote)\n",
        "auc_hybrid_smote = roc_auc_score(y_test, y_pred_probs_hybrid_smote)\n",
        "\n",
        "print(\"Confusion Matrix (SMOTE):\")\n",
        "print(cm_hybrid_smote)"
      ],
      "metadata": {
        "id": "rQlrSWcBZewT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN + LSTM + ADASYN"
      ],
      "metadata": {
        "id": "Hv1szcAEaNV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_adas_hybrid = X_train_adas.values.reshape((X_train_adas.shape[0], X_train_adas.shape[1], 1))\n"
      ],
      "metadata": {
        "id": "e_cdQO-gZeyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining EarlyStopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "# Defining model\n",
        "cnn_lstm_adas = Sequential()\n",
        "\n",
        "# Conv Block 1\n",
        "cnn_lstm_adas.add(Conv1D(32, 3, activation='relu', padding='same',\n",
        "                         input_shape=(X_train_adas_hybrid.shape[1], 1)))\n",
        "cnn_lstm_adas.add(BatchNormalization())\n",
        "cnn_lstm_adas.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
        "cnn_lstm_adas.add(BatchNormalization())\n",
        "cnn_lstm_adas.add(MaxPooling1D(pool_size=2))\n",
        "cnn_lstm_adas.add(Dropout(0.3))\n",
        "\n",
        "# Conv Block 2\n",
        "cnn_lstm_adas.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_lstm_adas.add(BatchNormalization())\n",
        "cnn_lstm_adas.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_lstm_adas.add(BatchNormalization())\n",
        "cnn_lstm_adas.add(MaxPooling1D(pool_size=2))\n",
        "cnn_lstm_adas.add(Dropout(0.3))\n",
        "\n",
        "# LSTM stack\n",
        "cnn_lstm_adas.add(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1))\n",
        "cnn_lstm_adas.add(BatchNormalization())\n",
        "cnn_lstm_adas.add(LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1))\n",
        "cnn_lstm_adas.add(BatchNormalization())\n",
        "\n",
        "# Dense head\n",
        "cnn_lstm_adas.add(Dense(128, activation='relu'))\n",
        "cnn_lstm_adas.add(Dropout(0.4))\n",
        "cnn_lstm_adas.add(Dense(64, activation='relu'))\n",
        "cnn_lstm_adas.add(Dropout(0.3))\n",
        "cnn_lstm_adas.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "_iJYjfFrZe1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "cnn_lstm_adas.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                      metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting model with early stopping\n",
        "cnn_lstm_adas.fit(\n",
        "    X_train_adas_hybrid,\n",
        "    y_train_adas,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_hybrid_adas = cnn_lstm_adas.predict(X_test_hybrid).flatten()\n",
        "y_pred_hybrid_adas = (y_pred_probs_hybrid_adas > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "-UCBUNVyZe4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_hybrid_adas = confusion_matrix(y_test, y_pred_hybrid_adas)\n",
        "roc_hybrid_adas = roc_curve(y_test, y_pred_probs_hybrid_adas)\n",
        "auc_hybrid_adas = roc_auc_score(y_test, y_pred_probs_hybrid_adas)\n",
        "\n",
        "print(\"Confusion Matrix (ADASYN):\")\n",
        "print(cm_hybrid_adas)"
      ],
      "metadata": {
        "id": "4vjNWpK-Ze6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cost-sensitive CNN + LSTM"
      ],
      "metadata": {
        "id": "tNTZUX3XaaS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining EarlyStopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "# Defining model\n",
        "cnn_lstm_cost = Sequential()\n",
        "\n",
        "# Conv Block 1\n",
        "cnn_lstm_cost.add(Conv1D(32, 3, activation='relu', padding='same',\n",
        "                         input_shape=(X_train_hybrid.shape[1], 1)))\n",
        "cnn_lstm_cost.add(BatchNormalization())\n",
        "cnn_lstm_cost.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
        "cnn_lstm_cost.add(BatchNormalization())\n",
        "cnn_lstm_cost.add(MaxPooling1D(pool_size=2))\n",
        "cnn_lstm_cost.add(Dropout(0.3))\n",
        "\n",
        "# Conv Block 2\n",
        "cnn_lstm_cost.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_lstm_cost.add(BatchNormalization())\n",
        "cnn_lstm_cost.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
        "cnn_lstm_cost.add(BatchNormalization())\n",
        "cnn_lstm_cost.add(MaxPooling1D(pool_size=2))\n",
        "cnn_lstm_cost.add(Dropout(0.3))\n",
        "\n",
        "# LSTM stack\n",
        "cnn_lstm_cost.add(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1))\n",
        "cnn_lstm_cost.add(BatchNormalization())\n",
        "cnn_lstm_cost.add(LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1))\n",
        "cnn_lstm_cost.add(BatchNormalization())\n",
        "\n",
        "# Dense head\n",
        "cnn_lstm_cost.add(Dense(128, activation='relu'))\n",
        "cnn_lstm_cost.add(Dropout(0.4))\n",
        "cnn_lstm_cost.add(Dense(64, activation='relu'))\n",
        "cnn_lstm_cost.add(Dropout(0.3))\n",
        "cnn_lstm_cost.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "E_DvhB_6Ze9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "cnn_lstm_cost.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                      metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting with class weights + early stopping\n",
        "cnn_lstm_cost.fit(\n",
        "    X_train_hybrid,\n",
        "    y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weights_dict,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_hybrid_cost = cnn_lstm_cost.predict(X_test_hybrid).flatten()\n",
        "y_pred_hybrid_cost = (y_pred_probs_hybrid_cost > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "PhMlSQt6aZIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_hybrid_cost = confusion_matrix(y_test, y_pred_hybrid_cost)\n",
        "roc_hybrid_cost = roc_curve(y_test, y_pred_probs_hybrid_cost)\n",
        "auc_hybrid_cost = roc_auc_score(y_test, y_pred_probs_hybrid_cost)\n",
        "\n",
        "print(\"Confusion Matrix (Cost-sensitive):\")\n",
        "print(cm_hybrid_cost)"
      ],
      "metadata": {
        "id": "LUPtScnEaZKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC Curve for All CNN+LSTM Models"
      ],
      "metadata": {
        "id": "UzPqq_E_aosc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(roc_hybrid[0], roc_hybrid[1], label='Baseline', linewidth=2)\n",
        "plt.plot(roc_hybrid_smote[0], roc_hybrid_smote[1], label='SMOTE', linewidth=2)\n",
        "plt.plot(roc_hybrid_adas[0], roc_hybrid_adas[1], label='ADASYN', linewidth=2)\n",
        "plt.plot(roc_hybrid_cost[0], roc_hybrid_cost[1], label='Cost-sensitive', linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.title('ROC Curves for CNN+LSTM Models (Healthcare Fraud)')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q2wab0KdaZNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics Comparison Table for CNN+LSTM Models"
      ],
      "metadata": {
        "id": "QIKkovDPar6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_cnn_lstm_fraud = pd.DataFrame({\n",
        "    \"Method\": [\"Baseline\", \"SMOTE\", \"ADASYN\", \"Cost-sensitive\"],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_test, y_pred_hybrid),\n",
        "        accuracy_score(y_test, y_pred_hybrid_smote),\n",
        "        accuracy_score(y_test, y_pred_hybrid_adas),\n",
        "        accuracy_score(y_test, y_pred_hybrid_cost)\n",
        "    ],\n",
        "    \"Precision\": [\n",
        "        precision_score(y_test, y_pred_hybrid),\n",
        "        precision_score(y_test, y_pred_hybrid_smote),\n",
        "        precision_score(y_test, y_pred_hybrid_adas),\n",
        "        precision_score(y_test, y_pred_hybrid_cost)\n",
        "    ],\n",
        "    \"Recall\": [\n",
        "        recall_score(y_test, y_pred_hybrid),\n",
        "        recall_score(y_test, y_pred_hybrid_smote),\n",
        "        recall_score(y_test, y_pred_hybrid_adas),\n",
        "        recall_score(y_test, y_pred_hybrid_cost)\n",
        "    ],\n",
        "    \"F1\": [\n",
        "        f1_score(y_test, y_pred_hybrid),\n",
        "        f1_score(y_test, y_pred_hybrid_smote),\n",
        "        f1_score(y_test, y_pred_hybrid_adas),\n",
        "        f1_score(y_test, y_pred_hybrid_cost)\n",
        "    ],\n",
        "    \"AUC\": [\n",
        "        auc_hybrid,\n",
        "        auc_hybrid_smote,\n",
        "        auc_hybrid_adas,\n",
        "        auc_hybrid_cost\n",
        "    ]\n",
        "})\n",
        "print(results_cnn_lstm_fraud)"
      ],
      "metadata": {
        "id": "3fNFtnUtaZPt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGADp+Cwhg3CCDKveEBRdu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}