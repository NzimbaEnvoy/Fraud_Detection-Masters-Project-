{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPFKysEm9JgEK1Cc469jZZQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NzimbaEnvoy/Fraud_Detection-Masters-Project-/blob/main/Telecoms_Fraud_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFwW-sPPzP4X"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM, TimeDistributed, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import itertools\n",
        "import shap\n"
      ],
      "metadata": {
        "id": "KfbdVroPzsZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the files\n",
        "base_path = \"/content/drive/MyDrive/Thesis Project\"\n",
        "\n",
        "train_path = os.path.join(base_path, \"train_data_telecom.csv\")\n",
        "test_path = os.path.join(base_path, \"test_data_telecom.csv\")\n",
        "\n",
        "# Loading data\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "train_df.head(5)"
      ],
      "metadata": {
        "id": "B-_Z10RuzscF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.drop(\"isFraud\", axis=1)\n",
        "y_train = train_df[\"isFraud\"]\n",
        "X_test = test_df.drop(\"isFraud\", axis=1)\n",
        "y_test = test_df[\"isFraud\"]"
      ],
      "metadata": {
        "id": "3ZGOzxejzseY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN BASELINE"
      ],
      "metadata": {
        "id": "SFHWLXbH0Kbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping input\n",
        "X_train_cnn = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_cnn  = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))"
      ],
      "metadata": {
        "id": "nbsNy2nkzsi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# CNN Model Architecture\n",
        "cnn_baseline = Sequential([\n",
        "    # Block 1\n",
        "    Conv1D(32, 3, activation='relu', padding='same', input_shape=(X_train_cnn.shape[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(64, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Block 2\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "LFSQU7z0zsjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling\n",
        "cnn_baseline.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
        ")\n",
        "\n",
        "# Fitting with early stopping\n",
        "cnn_baseline.fit(\n",
        "    X_train_cnn,\n",
        "    y_train,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_cnn = cnn_baseline.predict(X_test_cnn).flatten()\n",
        "y_pred_cnn = (y_pred_probs_cnn > 0.5).astype(int)\n",
        "\n",
        "cm_cnn = confusion_matrix(y_test, y_pred_cnn)\n",
        "roc_cnn = roc_curve(y_test, y_pred_probs_cnn)\n",
        "auc_cnn = roc_auc_score(y_test, y_pred_probs_cnn)\n",
        "\n",
        "print(\"Confusion Matrix (Baseline):\")\n",
        "print(cm_cnn)"
      ],
      "metadata": {
        "id": "CeF8OGRFzsl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP ANALYSIS"
      ],
      "metadata": {
        "id": "tNjRfFV88ucr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract original feature names\n",
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "#Sample background and test data for SHAP\n",
        "background = X_train_cnn[np.random.choice(X_train_cnn.shape[0], 100, replace=False)]\n",
        "X_explain = X_test_cnn[np.random.choice(X_test_cnn.shape[0], 50, replace=False)]\n",
        "\n",
        "#Flattening the samples for KernelExplainer\n",
        "background_flat = background.reshape(background.shape[0], -1)\n",
        "X_explain_flat = X_explain.reshape(X_explain.shape[0], -1)\n",
        "\n",
        "#Defining prediction wrapper for CNN\n",
        "def cnn_baseline_predict(x_flat):\n",
        "    x_reshaped = x_flat.reshape((-1, X_train_cnn.shape[1], 1))\n",
        "    return cnn_baseline.predict(x_reshaped).flatten()\n",
        "\n",
        "#Create SHAP KernelExplainer\n",
        "explainer = shap.KernelExplainer(cnn_baseline_predict, background_flat)\n",
        "\n",
        "#Compute SHAP values\n",
        "shap_values = explainer.shap_values(X_explain_flat)"
      ],
      "metadata": {
        "id": "PIMm6B8J0iMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SHAP Summary Plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_explain_flat,\n",
        "    feature_names=feature_names,\n",
        "    plot_type=\"dot\"\n",
        ")\n",
        "plt.title(\"SHAP Summary Plot - CNN (Baseline/No Class Balance)\", fontsize=10)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "6-bVWo900iOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN + SMOTE"
      ],
      "metadata": {
        "id": "fIki44Zg0i9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=123)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "X_train_smote_cnn = X_train_smote.values.reshape((X_train_smote.shape[0], X_train_smote.shape[1], 1))"
      ],
      "metadata": {
        "id": "1NSg2JAYzsoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining early stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Defining model\n",
        "cnn_smote = Sequential([\n",
        "    # Block 1\n",
        "    Conv1D(32, 3, activation='relu', padding='same', input_shape=(X_train_smote_cnn.shape[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(64, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Block 2\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "TOiXMiXXzsq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling\n",
        "cnn_smote.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting with early stopping\n",
        "cnn_smote.fit(\n",
        "    X_train_smote_cnn,\n",
        "    y_train_smote,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_smote = cnn_smote.predict(X_test_cnn).flatten()\n",
        "y_pred_smote = (y_pred_probs_smote > 0.5).astype(int)\n",
        "\n",
        "cm_smote = confusion_matrix(y_test, y_pred_smote)\n",
        "roc_smote = roc_curve(y_test, y_pred_probs_smote)\n",
        "auc_smote = roc_auc_score(y_test, y_pred_probs_smote)\n",
        "\n",
        "print(\"Confusion Matrix (SMOTE):\")\n",
        "print(cm_smote)"
      ],
      "metadata": {
        "id": "spWNnfdqzstf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the trained model\n",
        "import os\n",
        "model_dir = \"/content/drive/My Drive/Thesis Project\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "cnn_smote.save(f\"{model_dir}/cnn_smote_model.h5\")\n",
        "print(\"Model saved to:\", f\"{model_dir}/cnn_smote_model.h5\")"
      ],
      "metadata": {
        "id": "vxRz_kyg2CQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REALTIME INFERENCE"
      ],
      "metadata": {
        "id": "26ixupbW1RYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Loading saved CNN (SMOTE) model\n",
        "model_path = \"/content/drive/My Drive/Thesis Project/cnn_smote_model.h5\"\n",
        "cnn_smote = load_model(model_path)\n",
        "\n",
        "X_test_np = X_test.values.astype(\"float32\")\n",
        "y_test_np = y_test.values.astype(\"int32\")\n",
        "\n",
        "# Shape\n",
        "if X_test_np.ndim == 2:\n",
        "    X_test_np = X_test_np.reshape((X_test_np.shape[0], X_test_np.shape[1], 1))\n",
        "\n",
        "fraud_idx = np.where(y_test_np == 1)[0]\n",
        "assert fraud_idx.size > 0, \"No fraud rows in the test set.\"\n",
        "fraud_pool_X = X_test_np[fraud_idx]\n",
        "\n",
        "#Simulation settings\n",
        "domain_name  = \"telecoms\"\n",
        "lambda_fraud = 545.8\n",
        "runs         = 10_000\n",
        "threshold    = 0.50\n",
        "rng = np.random.default_rng(123)\n",
        "\n",
        "#Monte Carlo\n",
        "arrivals_F   = rng.poisson(lam=lambda_fraud, size=runs)\n",
        "tp_vec       = np.zeros(runs, dtype=int)\n",
        "det_rate_pct = np.full(runs, np.nan, dtype=float)\n",
        "\n",
        "for r in range(runs):\n",
        "    F = arrivals_F[r]\n",
        "    if F == 0:\n",
        "        continue\n",
        "    s_idx = rng.choice(fraud_pool_X.shape[0], size=F, replace=True)\n",
        "    X_r   = fraud_pool_X[s_idx]\n",
        "\n",
        "    # Predicting probabilities; assumes model outputs sigmoid probabilities\n",
        "    p_r  = cnn_smote.predict(X_r, verbose=0).reshape(-1)\n",
        "    yhat = (p_r >= threshold).astype(int)\n",
        "\n",
        "    TP = int(yhat.sum())\n",
        "    tp_vec[r]       = TP\n",
        "    det_rate_pct[r] = 100.0 * TP / F\n",
        "\n",
        "mc_df   = pd.DataFrame({\n",
        "    \"run\": np.arange(1, runs+1),\n",
        "    \"fraud_arrivals\": arrivals_F,\n",
        "    \"tp\": tp_vec,\n",
        "    \"detection_pct\": det_rate_pct\n",
        "})\n",
        "plot_df = mc_df.dropna(subset=[\"detection_pct\"])"
      ],
      "metadata": {
        "id": "X3gRfjjfzsv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary table\n",
        "summary_table = pd.DataFrame([{\n",
        "    \"model\": \"CNN (SMOTE)\",\n",
        "    \"threshold\": threshold,\n",
        "    \"mean_detection_pct\": plot_df[\"detection_pct\"].mean(),\n",
        "    \"median_detection_pct\": plot_df[\"detection_pct\"].median(),\n",
        "    \"p05_detection_pct\": np.percentile(plot_df[\"detection_pct\"], 5),\n",
        "    \"p95_detection_pct\": np.percentile(plot_df[\"detection_pct\"], 95),\n",
        "    \"mean_tp_per_sec\": lambda_fraud * plot_df[\"detection_pct\"].mean() / 100.0,\n",
        "    \"p05_tp_per_sec\":  lambda_fraud * np.percentile(plot_df[\"detection_pct\"], 5)  / 100.0,\n",
        "    \"p95_tp_per_sec\":  lambda_fraud * np.percentile(plot_df[\"detection_pct\"], 95) / 100.0\n",
        "}])\n",
        "\n",
        "print(summary_table.to_string(index=False))"
      ],
      "metadata": {
        "id": "mcf747rW1P-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Histogram (counts per bin).\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.hist(plot_df[\"detection_pct\"].values, bins=40)\n",
        "plt.title(f\"Detection rate per second — Monte Carlo ({domain_name})\")\n",
        "plt.xlabel(\"Detection Rate per second (%)\")\n",
        "plt.ylabel(\"Count of runs\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T4XrpEuQ1QCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ECDF\n",
        "x = np.sort(plot_df[\"detection_pct\"].values)\n",
        "y = np.arange(1, x.size+1) / x.size\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(x, y)\n",
        "plt.title(f\"ECDF of per-second detection — Monte Carlo ({domain_name})\")\n",
        "plt.xlabel(\"Detection Rate per second (%)\")\n",
        "plt.ylabel(\"ECDF\")\n",
        "plt.ylim(0, 1)\n",
        "plt.tight_layout()\n",
        "plt.show()$"
      ],
      "metadata": {
        "id": "TRzFQ_Zx1QKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#Load model + test data\n",
        "model_path = \"/content/drive/My Drive/Thesis Project/cnn_smote_model.h5\"\n",
        "cnn_smote = load_model(model_path)\n",
        "\n",
        "X_test_np = X_test.values.astype(\"float32\") if hasattr(X_test, \"values\") else np.asarray(X_test, dtype=\"float32\")\n",
        "y_test_np = y_test.values.astype(\"int32\")   if hasattr(y_test, \"values\") else np.asarray(y_test, dtype=\"int32\")\n",
        "\n",
        "#labels\n",
        "assert set(np.unique(y_test_np)).issubset({0, 1}), \"y_test must be binary {0,1}\"\n",
        "assert X_test_np.shape[0] == y_test_np.shape[0]\n",
        "\n",
        "# If model expects (n, timesteps, channels) and X is 2D, add channel dim\n",
        "def _ensure_cnn_shape(model, X):\n",
        "    in_shape = model.input_shape\n",
        "    if X.ndim == 2 and len(in_shape) == 3:\n",
        "        return np.expand_dims(X, axis=-1)\n",
        "    return X\n",
        "\n",
        "X_test_np = _ensure_cnn_shape(cnn_smote, X_test_np)\n",
        "\n",
        "# 2) Simulation settings\n",
        "lambda_per_sec = 545.8\n",
        "runs           = 10_000\n",
        "thr_cnn        = 0.50\n",
        "rng            = np.random.default_rng(123)\n"
      ],
      "metadata": {
        "id": "dR7VCGXBjwTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Probability helper\n",
        "def predict_prob_keras(model, X_batch, batch_size=4096):\n",
        "    \"\"\"Return p(y=1) for a Keras model (handles (n,1) or (n,) outputs).\"\"\"\n",
        "    p = model.predict(X_batch, batch_size=batch_size, verbose=0)\n",
        "    return np.asarray(p).reshape(-1)\n"
      ],
      "metadata": {
        "id": "pa6kfVV9jwWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Windowed Monte Carlo simulator\n",
        "def simulate_realtime_fullpool_keras(model, threshold, lambda_rate_per_sec, runs,\n",
        "                                     X_pool, y_pool, window_secs=1):\n",
        "    \"\"\"\n",
        "    Each run is a time window of length `window_secs`.\n",
        "    arrivals ~ Poisson(lambda_rate_per_sec * window_secs)\n",
        "    \"\"\"\n",
        "    N = X_pool.shape[0]\n",
        "    arrivals = rng.poisson(lam=lambda_rate_per_sec * window_secs, size=runs)\n",
        "\n",
        "    TP = np.zeros(runs, dtype=np.int32)\n",
        "    FP = np.zeros(runs, dtype=np.int32)\n",
        "    TN = np.zeros(runs, dtype=np.int32)\n",
        "    FN = np.zeros(runs, dtype=np.int32)\n",
        "\n",
        "    precision = np.full(runs, np.nan)\n",
        "    recall    = np.full(runs, np.nan)\n",
        "    accuracy  = np.full(runs, np.nan)\n",
        "    f1        = np.full(runs, np.nan)\n",
        "    auc_vec   = np.full(runs, np.nan)\n",
        "\n",
        "    for r in range(runs):\n",
        "        F = arrivals[r]\n",
        "        if F == 0:\n",
        "            continue\n",
        "\n",
        "        idx  = rng.integers(0, N, size=F, dtype=np.int64)\n",
        "        X_r  = X_pool[idx]\n",
        "        y_r  = y_pool[idx]\n",
        "        p_r  = predict_prob_keras(model, X_r)\n",
        "        yhat = (p_r >= threshold).astype(np.int32)\n",
        "\n",
        "        tp = np.sum((yhat == 1) & (y_r == 1))\n",
        "        fp = np.sum((yhat == 1) & (y_r == 0))\n",
        "        tn = np.sum((yhat == 0) & (y_r == 0))\n",
        "        fn = np.sum((yhat == 0) & (y_r == 1))\n",
        "\n",
        "        TP[r], FP[r], TN[r], FN[r] = tp, fp, tn, fn\n",
        "\n",
        "        if (tp + fp) > 0:\n",
        "            precision[r] = tp / (tp + fp)\n",
        "        if (tp + fn) > 0:\n",
        "            recall[r] = tp / (tp + fn)\n",
        "\n",
        "        accuracy[r] = (tp + tn) / F\n",
        "        if not np.isnan(precision[r]) and not np.isnan(recall[r]) and (precision[r] + recall[r]) > 0:\n",
        "            f1[r] = 2 * precision[r] * recall[r] / (precision[r] + recall[r])\n",
        "\n",
        "        # AUC only if both classes present in the window\n",
        "        if (y_r.min() == 0) and (y_r.max() == 1):\n",
        "            try:\n",
        "                auc_vec[r] = roc_auc_score(y_r, p_r)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    mc_df = pd.DataFrame({\n",
        "        \"run\": np.arange(1, runs+1, dtype=np.int32),\n",
        "        \"window_secs\": window_secs,\n",
        "        \"arrivals\": arrivals,\n",
        "        \"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN,\n",
        "        \"precision\": precision, \"recall\": recall, \"accuracy\": accuracy, \"f1\": f1,\n",
        "        \"auc\": auc_vec\n",
        "    })\n",
        "\n",
        "    summary = {\n",
        "        \"runs\": runs,\n",
        "        \"window_secs\": window_secs,\n",
        "        \"runs_with_tx\": int(np.sum(arrivals > 0)),\n",
        "        \"mean_TP\": float(np.nanmean(TP)),\n",
        "        \"mean_FP\": float(np.nanmean(FP)),\n",
        "        \"mean_TN\": float(np.nanmean(TN)),\n",
        "        \"mean_FN\": float(np.nanmean(FN)),\n",
        "        \"mean_precision\": float(np.nanmean(precision)),\n",
        "        \"mean_recall\": float(np.nanmean(recall)),\n",
        "        \"mean_accuracy\": float(np.nanmean(accuracy)),\n",
        "        \"mean_f1\": float(np.nanmean(f1)),\n",
        "        \"mean_auc\": float(np.nanmean(auc_vec)),\n",
        "        \"median_auc\": float(np.nanmedian(auc_vec)),\n",
        "        \"n_auc_runs\": int(np.sum(~np.isnan(auc_vec))),\n",
        "    }\n",
        "    summary_df = pd.DataFrame([summary])\n",
        "    return {\"mc_df\": mc_df, \"summary\": summary_df}"
      ],
      "metadata": {
        "id": "d-xbY8dljwYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run CNN at 1s and 10s windows\n",
        "res_cnn_1s  = simulate_realtime_fullpool_keras(\n",
        "    model=cnn_smote, threshold=thr_cnn, lambda_rate_per_sec=lambda_per_sec,\n",
        "    runs=runs, X_pool=X_test_np, y_pool=y_test_np, window_secs=1\n",
        ")\n",
        "res_cnn_10s = simulate_realtime_fullpool_keras(\n",
        "    model=cnn_smote, threshold=thr_cnn, lambda_rate_per_sec=lambda_per_sec,\n",
        "    runs=runs, X_pool=X_test_np, y_pool=y_test_np, window_secs=10\n",
        ")"
      ],
      "metadata": {
        "id": "8_x2tqv0jwjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare summaries\n",
        "summary_table = pd.concat([\n",
        "    res_cnn_1s[\"summary\"].assign(model=\"CNN (SMOTE, telecoms)\", time_unit=\"1 sec\",  threshold=thr_cnn),\n",
        "    res_cnn_10s[\"summary\"].assign(model=\"CNN (SMOTE, telecoms)\", time_unit=\"10 sec\", threshold=thr_cnn),\n",
        "], ignore_index=True)[[\n",
        "    \"model\",\"time_unit\",\n",
        "    \"mean_accuracy\",\"mean_precision\",\"mean_recall\",\"mean_f1\",\n",
        "    \"mean_auc\"\n",
        "]]\n",
        "\n",
        "print(summary_table.to_string(index=False))"
      ],
      "metadata": {
        "id": "R1uKGOIvjwmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP ANALYSIS"
      ],
      "metadata": {
        "id": "6jp9Pp_J9tBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract feature names\n",
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "#Sample background and test data\n",
        "background_smote = X_train_smote_cnn[np.random.choice(X_train_smote_cnn.shape[0], 100, replace=False)]\n",
        "X_explain_smote = X_test_cnn[np.random.choice(X_test_cnn.shape[0], 50, replace=False)]\n",
        "\n",
        "#Flatten for SHAP KernelExplainer\n",
        "background_smote_flat = background_smote.reshape(background_smote.shape[0], -1)\n",
        "X_explain_smote_flat = X_explain_smote.reshape(X_explain_smote.shape[0], -1)\n",
        "\n",
        "#Define model prediction wrapper\n",
        "def cnn_smote_predict(x_flat):\n",
        "    x_reshaped = x_flat.reshape((-1, X_train_smote_cnn.shape[1], 1))\n",
        "    return cnn_smote.predict(x_reshaped).flatten()\n",
        "\n",
        "#Create SHAP explainer\n",
        "explainer_smote = shap.KernelExplainer(cnn_smote_predict, background_smote_flat)\n",
        "\n",
        "#Compute SHAP values\n",
        "shap_values_smote = explainer_smote.shap_values(X_explain_smote_flat)"
      ],
      "metadata": {
        "id": "WxrUvhsozsye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SHAP Summary Plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "shap.summary_plot(\n",
        "    shap_values_smote,\n",
        "    X_explain_smote_flat,\n",
        "    feature_names=feature_names,\n",
        "    plot_type=\"dot\"\n",
        ")\n",
        "plt.title(\"SHAP Summary Plot - CNN (SMOTE)\", fontsize=12)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "DP4CALyizs1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN + ADASYN"
      ],
      "metadata": {
        "id": "ICoEDMuP07IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adas = ADASYN(random_state=123)\n",
        "X_train_adas, y_train_adas = adas.fit_resample(X_train, y_train)\n",
        "X_train_adas_cnn = X_train_adas.values.reshape((X_train_adas.shape[0], X_train_adas.shape[1], 1))"
      ],
      "metadata": {
        "id": "_e2Elth1zs3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# CNN Model for ADASYN\n",
        "cnn_adas = Sequential([\n",
        "    # Block 1\n",
        "    Conv1D(32, 3, activation='relu', padding='same', input_shape=(X_train_adas_cnn.shape[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(64, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Block 2\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "rgqaFsrazs5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling\n",
        "cnn_adas.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                 metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting model with early stopping\n",
        "cnn_adas.fit(\n",
        "    X_train_adas_cnn,\n",
        "    y_train_adas,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_adas = cnn_adas.predict(X_test_cnn).flatten()\n",
        "y_pred_adas = (y_pred_probs_adas > 0.5).astype(int)\n",
        "\n",
        "cm_adas = confusion_matrix(y_test, y_pred_adas)\n",
        "roc_adas = roc_curve(y_test, y_pred_probs_adas)\n",
        "auc_adas = roc_auc_score(y_test, y_pred_probs_adas)\n",
        "\n",
        "print(\"Confusion Matrix (ADASYN):\")\n",
        "print(cm_adas)"
      ],
      "metadata": {
        "id": "JCVTuZ5pzs8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP ANALYSIS"
      ],
      "metadata": {
        "id": "S_YVt7-t-tOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Names\n",
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "#Sample Background and Test Data\n",
        "background_adas = X_train_adas_cnn[np.random.choice(X_train_adas_cnn.shape[0], 100, replace=False)]\n",
        "X_explain_adas = X_test_cnn[np.random.choice(X_test_cnn.shape[0], 50, replace=False)]\n",
        "\n",
        "#Flattening for KernelExplainer\n",
        "background_adas_flat = background_adas.reshape(background_adas.shape[0], -1)\n",
        "X_explain_adas_flat = X_explain_adas.reshape(X_explain_adas.shape[0], -1)\n",
        "\n",
        "#Defining Prediction Function\n",
        "def cnn_adas_predict(x_flat):\n",
        "    x_reshaped = x_flat.reshape((-1, X_train_adas_cnn.shape[1], 1))\n",
        "    return cnn_adas.predict(x_reshaped).flatten()\n",
        "\n",
        "#Creating SHAP Explainer\n",
        "explainer_adas = shap.KernelExplainer(cnn_adas_predict, background_adas_flat)\n",
        "\n",
        "#Computing SHAP Values\n",
        "shap_values_adas = explainer_adas.shap_values(X_explain_adas_flat)"
      ],
      "metadata": {
        "id": "846mPgD4zs_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SHAP Summary Plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "shap.summary_plot(\n",
        "    shap_values_adas,\n",
        "    X_explain_adas_flat,\n",
        "    feature_names=feature_names,\n",
        "    plot_type=\"dot\"\n",
        ")\n",
        "plt.title(\"SHAP Summary Plot - CNN (ADASYN)\", fontsize=10)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "H4AmU02zztB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost-sensitive CNN"
      ],
      "metadata": {
        "id": "lxum42n71UaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}"
      ],
      "metadata": {
        "id": "EME3lgakztEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Defining model\n",
        "cnn_cost = Sequential([\n",
        "    # Block 1\n",
        "    Conv1D(32, 3, activation='relu', padding='same', input_shape=(X_train_cnn.shape[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(64, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Block 2\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "LeLqankMztHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "cnn_cost.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                 metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting model with early stopping and class weights\n",
        "cnn_cost.fit(\n",
        "    X_train_cnn,\n",
        "    y_train,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_cost = cnn_cost.predict(X_test_cnn).flatten()\n",
        "y_pred_cost = (y_pred_probs_cost > 0.5).astype(int)\n",
        "\n",
        "cm_cost = confusion_matrix(y_test, y_pred_cost)\n",
        "roc_cost = roc_curve(y_test, y_pred_probs_cost)\n",
        "auc_cost = roc_auc_score(y_test, y_pred_probs_cost)\n",
        "\n",
        "print(\"Confusion Matrix (Cost-sensitive):\")\n",
        "print(cm_cost)"
      ],
      "metadata": {
        "id": "JONp00n-ztJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP ANALYSIS"
      ],
      "metadata": {
        "id": "uokDgjiK_Wgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Names\n",
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "#Sample background and test data for SHAP\n",
        "background_cost = X_train_cnn[np.random.choice(X_train_cnn.shape[0], 100, replace=False)]\n",
        "X_explain_cost = X_test_cnn[np.random.choice(X_test_cnn.shape[0], 50, replace=False)]\n",
        "\n",
        "#Flattening for SHAP\n",
        "background_cost_flat = background_cost.reshape(background_cost.shape[0], -1)\n",
        "X_explain_cost_flat = X_explain_cost.reshape(X_explain_cost.shape[0], -1)\n",
        "\n",
        "#Defining prediction function\n",
        "def cnn_cost_predict(x_flat):\n",
        "    x_reshaped = x_flat.reshape((-1, X_train_cnn.shape[1], 1))\n",
        "    return cnn_cost.predict(x_reshaped).flatten()\n",
        "\n",
        "#Creating SHAP Explainer\n",
        "explainer_cost = shap.KernelExplainer(cnn_cost_predict, background_cost_flat)\n",
        "\n",
        "#Computing SHAP values\n",
        "shap_values_cost = explainer_cost.shap_values(X_explain_cost_flat)\n"
      ],
      "metadata": {
        "id": "vTEN3uQ8_VqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SHAP Summary Plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "shap.summary_plot(\n",
        "    shap_values_cost,\n",
        "    X_explain_cost_flat,\n",
        "    feature_names=feature_names,\n",
        "    plot_type=\"dot\"\n",
        ")\n",
        "plt.title(\"SHAP Summary Plot - CNN (Cost-Sensitive)\", fontsize=12)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "5bzI2UfU_VwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wv5enOZAztMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROC Plot (CNN Models on Telecom Fraud)"
      ],
      "metadata": {
        "id": "1ReGCtsX13Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(roc_cnn[0], roc_cnn[1], label=\"Baseline\", linewidth=2)\n",
        "plt.plot(roc_smote[0], roc_smote[1], label=\"SMOTE\", linewidth=2)\n",
        "plt.plot(roc_adas[0], roc_adas[1], label=\"ADASYN\", linewidth=2)\n",
        "plt.plot(roc_cost[0], roc_cost[1], label=\"Cost-sensitive\", linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.title(\"ROC Curves for CNN Models (Telecom Fraud)\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IkLb-Gm_ztOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics Comparison Table (CNN Models)"
      ],
      "metadata": {
        "id": "FaxymBxe1-J0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_cnn_telecom = pd.DataFrame({\n",
        "    \"Method\": [\"Baseline\", \"SMOTE\", \"ADASYN\", \"Cost-sensitive\"],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_test, y_pred_cnn),\n",
        "        accuracy_score(y_test, y_pred_smote),\n",
        "        accuracy_score(y_test, y_pred_adas),\n",
        "        accuracy_score(y_test, y_pred_cost)\n",
        "    ],\n",
        "    \"Precision\": [\n",
        "        precision_score(y_test, y_pred_cnn),\n",
        "        precision_score(y_test, y_pred_smote),\n",
        "        precision_score(y_test, y_pred_adas),\n",
        "        precision_score(y_test, y_pred_cost)\n",
        "    ],\n",
        "    \"Recall\": [\n",
        "        recall_score(y_test, y_pred_cnn),\n",
        "        recall_score(y_test, y_pred_smote),\n",
        "        recall_score(y_test, y_pred_adas),\n",
        "        recall_score(y_test, y_pred_cost)\n",
        "    ],\n",
        "    \"F1\": [\n",
        "        f1_score(y_test, y_pred_cnn),\n",
        "        f1_score(y_test, y_pred_smote),\n",
        "        f1_score(y_test, y_pred_adas),\n",
        "        f1_score(y_test, y_pred_cost)\n",
        "    ],\n",
        "    \"AUC\": [\n",
        "        auc_cnn,\n",
        "        auc_smote,\n",
        "        auc_adas,\n",
        "        auc_cost\n",
        "    ]\n",
        "\n",
        "})\n",
        "print(results_cnn_telecom)"
      ],
      "metadata": {
        "id": "kRVRFhkbztQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM MODELS"
      ],
      "metadata": {
        "id": "W2x0vsHu2f59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM BASELINE"
      ],
      "metadata": {
        "id": "MUZ9VBOK2mC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping input for LSTM\n",
        "X_train_lstm = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_lstm  = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))"
      ],
      "metadata": {
        "id": "yyN48sr0ztV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# LSTM model\n",
        "lstm_baseline = Sequential([\n",
        "    # LSTM Block 1\n",
        "    LSTM(128, input_shape=(X_train_lstm.shape[1], 1),\n",
        "         return_sequences=True, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # LSTM Block 2\n",
        "    LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # LSTM Block 3 (final, no return_sequences)\n",
        "    LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # Dense head\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "Zxj5lj7BztYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "lstm_baseline.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                      metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting model\n",
        "lstm_baseline.fit(\n",
        "    X_train_lstm,\n",
        "    y_train,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_lstm = lstm_baseline.predict(X_test_lstm).flatten()\n",
        "y_pred_lstm = (y_pred_probs_lstm > 0.5).astype(int)\n",
        "\n",
        "cm_lstm = confusion_matrix(y_test, y_pred_lstm)\n",
        "roc_lstm = roc_curve(y_test, y_pred_probs_lstm)\n",
        "auc_lstm = roc_auc_score(y_test, y_pred_probs_lstm)\n",
        "\n",
        "print(\"Confusion Matrix (Baseline):\")\n",
        "print(cm_lstm)"
      ],
      "metadata": {
        "id": "JjOZ8K7Izta0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM + SMOTE"
      ],
      "metadata": {
        "id": "RMD4-fTB26XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_smote_lstm = X_train_smote.values.reshape((X_train_smote.shape[0], X_train_smote.shape[1], 1))"
      ],
      "metadata": {
        "id": "4tzJey-R2t-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping setup\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# LSTM model\n",
        "lstm_smote = Sequential([\n",
        "    # LSTM Block 1\n",
        "    LSTM(128, input_shape=(X_train_smote_lstm.shape[1], 1),\n",
        "         return_sequences=True, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # LSTM Block 2\n",
        "    LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # LSTM Block 3 (final, no return_sequences)\n",
        "    LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # Dense head\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "Np4GINVH2uAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "lstm_smote.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                   metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting model\n",
        "lstm_smote.fit(\n",
        "    X_train_smote_lstm,\n",
        "    y_train_smote,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_smote = lstm_smote.predict(X_test_lstm).flatten()\n",
        "y_pred_smote = (y_pred_probs_smote > 0.5).astype(int)\n",
        "\n",
        "cm_smote = confusion_matrix(y_test, y_pred_smote)\n",
        "roc_smote = roc_curve(y_test, y_pred_probs_smote)\n",
        "auc_smote = roc_auc_score(y_test, y_pred_probs_smote)\n",
        "\n",
        "print(\"Confusion Matrix (SMOTE):\")\n",
        "print(cm_smote)"
      ],
      "metadata": {
        "id": "C5Kw0MKw2uDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM + ADASYN"
      ],
      "metadata": {
        "id": "K6dvLu7g3LNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_adas_lstm = X_train_adas.values.reshape((X_train_adas.shape[0], X_train_adas.shape[1], 1))"
      ],
      "metadata": {
        "id": "dttF9rja2uK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "#LSTM Architecture\n",
        "lstm_adas = Sequential([\n",
        "    # LSTM Block 1\n",
        "    LSTM(128, input_shape=(X_train_adas_lstm.shape[1], 1),\n",
        "         return_sequences=True, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # LSTM Block 2\n",
        "    LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # LSTM Block 3\n",
        "    LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # Dense head\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "CYi0BMC02uNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "lstm_adas.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting model with early stopping and validation\n",
        "lstm_adas.fit(\n",
        "    X_train_adas_lstm,\n",
        "    y_train_adas,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_adas = lstm_adas.predict(X_test_lstm).flatten()\n",
        "y_pred_adas = (y_pred_probs_adas > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "paPFyeGr2uP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM COST"
      ],
      "metadata": {
        "id": "33Tz4I7XQrWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "lstm_cost = Sequential([\n",
        "    # LSTM Block 1\n",
        "    LSTM(128, input_shape=(X_train_lstm.shape[1], 1),\n",
        "         return_sequences=True, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # LSTM Block 2\n",
        "    LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # LSTM Block 3\n",
        "    LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # Dense head\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "3DgoU3yO2uSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "lstm_cost.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting model with early stopping & class weights\n",
        "lstm_cost.fit(\n",
        "    X_train_lstm,\n",
        "    y_train,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_cost = lstm_cost.predict(X_test_lstm).flatten()\n",
        "y_pred_cost = (y_pred_probs_cost > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "vHo3o5V42uUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_cost = confusion_matrix(y_test, y_pred_cost)\n",
        "roc_cost = roc_curve(y_test, y_pred_probs_cost)\n",
        "auc_cost = roc_auc_score(y_test, y_pred_probs_cost)\n",
        "\n",
        "print(\"Confusion Matrix (Cost-sensitive):\")\n",
        "print(cm_cost)"
      ],
      "metadata": {
        "id": "LWPfIZ_t2uXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC Curve for All LSTM Models"
      ],
      "metadata": {
        "id": "AwqtSpufQ___"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(roc_lstm[0], roc_lstm[1], label='Baseline', linewidth=2)\n",
        "plt.plot(roc_smote[0], roc_smote[1], label='SMOTE', linewidth=2)\n",
        "plt.plot(roc_adas[0], roc_adas[1], label='ADASYN', linewidth=2)\n",
        "plt.plot(roc_cost[0], roc_cost[1], label='Cost-sensitive', linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.title(\"ROC Curves for LSTM Models (Telecom Fraud)\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HrJHrRNl2uZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics Comparison Table for LSTM Models"
      ],
      "metadata": {
        "id": "21-b8zGORIvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_lstm_telecom = pd.DataFrame({\n",
        "    \"Method\": [\"Baseline\", \"SMOTE\", \"ADASYN\", \"Cost-sensitive\"],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_test, y_pred_lstm),\n",
        "        accuracy_score(y_test, y_pred_smote),\n",
        "        accuracy_score(y_test, y_pred_adas),\n",
        "        accuracy_score(y_test, y_pred_cost)\n",
        "    ],\n",
        "    \"Precision\": [\n",
        "        precision_score(y_test, y_pred_lstm),\n",
        "        precision_score(y_test, y_pred_smote),\n",
        "        precision_score(y_test, y_pred_adas),\n",
        "        precision_score(y_test, y_pred_cost)\n",
        "    ],\n",
        "    \"Recall\": [\n",
        "        recall_score(y_test, y_pred_lstm),\n",
        "        recall_score(y_test, y_pred_smote),\n",
        "        recall_score(y_test, y_pred_adas),\n",
        "        recall_score(y_test, y_pred_cost)\n",
        "    ],\n",
        "    \"F1\": [\n",
        "        f1_score(y_test, y_pred_lstm),\n",
        "        f1_score(y_test, y_pred_smote),\n",
        "        f1_score(y_test, y_pred_adas),\n",
        "        f1_score(y_test, y_pred_cost)\n",
        "    ],\n",
        "    \"AUC\": [\n",
        "        auc_lstm,\n",
        "        auc_smote,\n",
        "        auc_adas,\n",
        "        auc_cost\n",
        "    ]\n",
        "\n",
        "})\n",
        "print(results_lstm_telecom)"
      ],
      "metadata": {
        "id": "rmPfwD6l2ucF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN + LSTM hybrid"
      ],
      "metadata": {
        "id": "RGs3cvk0RScc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BASELINE MODEL"
      ],
      "metadata": {
        "id": "wG-VfCDMRWid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping input\n",
        "X_train_hybrid = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_hybrid  = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))"
      ],
      "metadata": {
        "id": "q3sTTG4Q2ueh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining early stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Defining enhanced CNN+LSTM model\n",
        "cnn_lstm_baseline = Sequential([\n",
        "    # Conv Block 1\n",
        "    Conv1D(32, 3, activation='relu', padding='same',\n",
        "           input_shape=(X_train_hybrid.shape[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(64, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Conv Block 2\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # LSTM stack\n",
        "    LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "    LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # Dense head\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "3zREvjHDRNdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "cnn_lstm_baseline.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                          metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting model with validation and early stopping\n",
        "cnn_lstm_baseline.fit(\n",
        "    X_train_hybrid,\n",
        "    y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_hybrid = cnn_lstm_baseline.predict(X_test_hybrid).flatten()\n",
        "y_pred_hybrid = (y_pred_probs_hybrid > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "7qCytH7DRNfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_hybrid = confusion_matrix(y_test, y_pred_hybrid)\n",
        "roc_hybrid = roc_curve(y_test, y_pred_probs_hybrid)\n",
        "auc_hybrid = roc_auc_score(y_test, y_pred_probs_hybrid)\n",
        "\n",
        "print(\"Confusion Matrix (Baseline):\")\n",
        "print(cm_hybrid)"
      ],
      "metadata": {
        "id": "1CsJpztTRNia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN + LSTM + SMOTE"
      ],
      "metadata": {
        "id": "Bj32j0JWRmwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_smote_hybrid = X_train_smote.values.reshape((X_train_smote.shape[0], X_train_smote.shape[1], 1))"
      ],
      "metadata": {
        "id": "-8jV6ywpRNlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping setup\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Defining model\n",
        "cnn_lstm_smote = Sequential([\n",
        "    # Conv Block 1\n",
        "    Conv1D(32, 3, activation='relu', padding='same',\n",
        "           input_shape=(X_train_smote_hybrid.shape[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(64, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Conv Block 2\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # LSTM stack\n",
        "    LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "    LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # Dense head\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "jVOwF6c0RNn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling\n",
        "cnn_lstm_smote.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                       metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting with early stopping\n",
        "cnn_lstm_smote.fit(\n",
        "    X_train_smote_hybrid,\n",
        "    y_train_smote,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting\n",
        "y_pred_probs_hybrid_smote = cnn_lstm_smote.predict(X_test_hybrid).flatten()\n",
        "y_pred_hybrid_smote = (y_pred_probs_hybrid_smote > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "j8Aa9V_xRNqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_hybrid_smote = confusion_matrix(y_test, y_pred_hybrid_smote)\n",
        "roc_hybrid_smote = roc_curve(y_test, y_pred_probs_hybrid_smote)\n",
        "auc_hybrid_smote = roc_auc_score(y_test, y_pred_probs_hybrid_smote)\n",
        "\n",
        "print(\"Confusion Matrix (SMOTE):\")\n",
        "print(cm_hybrid_smote)"
      ],
      "metadata": {
        "id": "jTHS-oUqRNtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN + LSTM + ADASYN"
      ],
      "metadata": {
        "id": "mPWWwEJqR5LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_adas_hybrid = X_train_adas.values.reshape((X_train_adas.shape[0], X_train_adas.shape[1], 1))"
      ],
      "metadata": {
        "id": "nXf_3sglRNv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup early stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Model\n",
        "cnn_lstm_adas = Sequential([\n",
        "    # Conv Block 1\n",
        "    Conv1D(32, 3, activation='relu', padding='same',\n",
        "           input_shape=(X_train_adas_hybrid.shape[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(64, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Conv Block 2\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # LSTM stack\n",
        "    LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "    LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # Dense head\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "TvcNAikfRNyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling\n",
        "cnn_lstm_adas.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                      metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting with early stopping and validation\n",
        "cnn_lstm_adas.fit(\n",
        "    X_train_adas_hybrid,\n",
        "    y_train_adas,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_hybrid_adas = cnn_lstm_adas.predict(X_test_hybrid).flatten()\n",
        "y_pred_hybrid_adas = (y_pred_probs_hybrid_adas > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "-MlKobP0RN1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_hybrid_adas = confusion_matrix(y_test, y_pred_hybrid_adas)\n",
        "roc_hybrid_adas = roc_curve(y_test, y_pred_probs_hybrid_adas)\n",
        "auc_hybrid_adas = roc_auc_score(y_test, y_pred_probs_hybrid_adas)\n",
        "\n",
        "print(\"Confusion Matrix (ADASYN):\")\n",
        "print(cm_hybrid_adas)"
      ],
      "metadata": {
        "id": "sK6pSaGTRN3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "30sPGcW3RN6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cost-sensitive CNN + LSTM"
      ],
      "metadata": {
        "id": "BKidM_vPSJdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining early stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "#Model\n",
        "cnn_lstm_cost = Sequential([\n",
        "    # Conv Block 1\n",
        "    Conv1D(32, 3, activation='relu', padding='same',\n",
        "           input_shape=(X_train_hybrid.shape[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(64, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Conv Block 2\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # LSTM stack\n",
        "    LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "    LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # Dense head\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "UuiebU58RN9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "cnn_lstm_cost.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
        "                      metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# Fitting with early stopping, class weights, validation\n",
        "cnn_lstm_cost.fit(\n",
        "    X_train_hybrid,\n",
        "    y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weights_dict,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicting & evaluation\n",
        "y_pred_probs_hybrid_cost = cnn_lstm_cost.predict(X_test_hybrid).flatten()\n",
        "y_pred_hybrid_cost = (y_pred_probs_hybrid_cost > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "zOckEOplRN_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_hybrid_cost = confusion_matrix(y_test, y_pred_hybrid_cost)\n",
        "roc_hybrid_cost = roc_curve(y_test, y_pred_probs_hybrid_cost)\n",
        "auc_hybrid_cost = roc_auc_score(y_test, y_pred_probs_hybrid_cost)\n",
        "\n",
        "print(\"Confusion Matrix (Cost-sensitive):\")\n",
        "print(cm_hybrid_cost)"
      ],
      "metadata": {
        "id": "jyWjiAdKROCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC Curve for All CNN+LSTM Models"
      ],
      "metadata": {
        "id": "pPe2PQ6ASVhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(roc_hybrid[0], roc_hybrid[1], label='Baseline', linewidth=2)\n",
        "plt.plot(roc_hybrid_smote[0], roc_hybrid_smote[1], label='SMOTE', linewidth=2)\n",
        "plt.plot(roc_hybrid_adas[0], roc_hybrid_adas[1], label='ADASYN', linewidth=2)\n",
        "plt.plot(roc_hybrid_cost[0], roc_hybrid_cost[1], label='Cost-sensitive', linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.title(\"ROC Curves for CNN+LSTM Models (Telecom Fraud)\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mh5p0SPfROEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics Comparison Table for CNN+LSTM Models"
      ],
      "metadata": {
        "id": "LItwFG5KSYzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_cnn_lstm_telecom = pd.DataFrame({\n",
        "    \"Method\": [\"Baseline\", \"SMOTE\", \"ADASYN\", \"Cost-sensitive\"],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_test, y_pred_hybrid),\n",
        "        accuracy_score(y_test, y_pred_hybrid_smote),\n",
        "        accuracy_score(y_test, y_pred_hybrid_adas),\n",
        "        accuracy_score(y_test, y_pred_hybrid_cost)\n",
        "    ],\n",
        "    \"Precision\": [\n",
        "        precision_score(y_test, y_pred_hybrid),\n",
        "        precision_score(y_test, y_pred_hybrid_smote),\n",
        "        precision_score(y_test, y_pred_hybrid_adas),\n",
        "        precision_score(y_test, y_pred_hybrid_cost)\n",
        "    ],\n",
        "    \"Recall\": [\n",
        "        recall_score(y_test, y_pred_hybrid),\n",
        "        recall_score(y_test, y_pred_hybrid_smote),\n",
        "        recall_score(y_test, y_pred_hybrid_adas),\n",
        "        recall_score(y_test, y_pred_hybrid_cost)\n",
        "    ],\n",
        "    \"F1\": [\n",
        "        f1_score(y_test, y_pred_hybrid),\n",
        "        f1_score(y_test, y_pred_hybrid_smote),\n",
        "        f1_score(y_test, y_pred_hybrid_adas),\n",
        "        f1_score(y_test, y_pred_hybrid_cost)\n",
        "    ],\n",
        "    \"AUC\": [\n",
        "        auc_hybrid,\n",
        "        auc_hybrid_smote,\n",
        "        auc_hybrid_adas,\n",
        "        auc_hybrid_cost\n",
        "    ]\n",
        "\n",
        "})\n",
        "print(results_cnn_lstm_telecom)"
      ],
      "metadata": {
        "id": "xP0K130dROH5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}